boxes: ƒê√¢y l√† tensor ch·ª©a c√°c th√¥ng tin v·ªÅ bounding boxes c·ªßa c√°c ƒë·ªëi t∆∞·ª£ng ƒë∆∞·ª£c ph√°t hi·ªán trong h√¨nh ·∫£nh. M·ªói d√≤ng c·ªßa tensor n√†y t∆∞∆°ng ·ª©ng v·ªõi m·ªôt bounding box v√† bao g·ªìm c√°c th√¥ng tin sau:

C·ªôt 1 v√† 2: T·ªça ƒë·ªô x v√† y c·ªßa g√≥c tr√™n b√™n tr√°i c·ªßa bounding box.
C·ªôt 3 v√† 4: T·ªça ƒë·ªô x v√† y c·ªßa g√≥c d∆∞·ªõi b√™n ph·∫£i c·ªßa bounding box.
C·ªôt 5: ƒê·ªô t·ª± tin (confidence) c·ªßa vi·ªác ph√°t hi·ªán.
C·ªôt 6: ID c·ªßa l·ªõp (class ID) c·ªßa ƒë·ªëi t∆∞·ª£ng ƒë∆∞·ª£c ph√°t hi·ªán.
cls: ƒê√¢y l√† tensor ch·ª©a ID c·ªßa l·ªõp c·ªßa c√°c ƒë·ªëi t∆∞·ª£ng ƒë∆∞·ª£c ph√°t hi·ªán.

conf: ƒê√¢y l√† tensor ch·ª©a gi√° tr·ªã ƒë·ªô t·ª± tin (confidence) c·ªßa c√°c ƒë·ªëi t∆∞·ª£ng ƒë∆∞·ª£c ph√°t hi·ªán.

data: T∆∞∆°ng t·ª± nh∆∞ boxes, ƒë√¢y l√† tensor ch·ª©a th√¥ng tin v·ªÅ bounding boxes c·ªßa c√°c ƒë·ªëi t∆∞·ª£ng, nh∆∞ng ƒë∆∞·ª£c t·ªï ch·ª©c theo c·∫•u tr√∫c tensor kh√°c.

id: ƒê√¢y l√† m·ªôt thu·ªôc t√≠nh (attribute) kh√¥ng c√≥ gi√° tr·ªã c·ª• th·ªÉ trong k·∫øt qu·∫£.

is_track: ƒê√¢y l√† m·ªôt thu·ªôc t√≠nh (attribute) ƒë√°nh d·∫•u xem li·ªáu c√°c bounding boxes c√≥ ph·∫£i l√† theo d√µi c√°c ƒë·ªëi t∆∞·ª£ng hay kh√¥ng.

orig_shape: ƒê√¢y l√† k√≠ch th∆∞·ªõc g·ªëc c·ªßa h√¨nh ·∫£nh tr∆∞·ªõc khi ƒë∆∞·ª£c x·ª≠ l√Ω b·ªüi m√¥ h√¨nh.

shape: ƒê√¢y l√† k√≠ch th∆∞·ªõc c·ªßa h√¨nh ·∫£nh sau khi ƒë∆∞·ª£c x·ª≠ l√Ω b·ªüi m√¥ h√¨nh.

xywh: ƒê√¢y l√† tensor ch·ª©a th√¥ng tin v·ªÅ t·ªça ƒë·ªô v√† k√≠ch th∆∞·ªõc c·ªßa bounding boxes d∆∞·ªõi d·∫°ng (x_center, y_center, width, height).

xywhn: ƒê√¢y l√† tensor ch·ª©a th√¥ng tin t∆∞∆°ng t·ª± xywh, nh∆∞ng ƒë∆∞·ª£c chu·∫©n h√≥a trong kho·∫£ng t·ª´ 0 ƒë·∫øn 1.

xyxy: ƒê√¢y l√† tensor ch·ª©a th√¥ng tin v·ªÅ t·ªça ƒë·ªô c·ªßa bounding boxes d∆∞·ªõi d·∫°ng (x_min, y_min, x_max, y_max).

xyxyn: ƒê√¢y l√† tensor ch·ª©a th√¥ng tin t∆∞∆°ng t·ª± xyxy, nh∆∞ng ƒë∆∞·ª£c chu·∫©n h√≥a trong kho·∫£ng t·ª´ 0 ƒë·∫øn 1.



Th√¥ng tin v·ªÅ mask trong ultralytics.engine.results.Masks bao g·ªìm:

data v√† masks: ƒê√¢y l√† hai tensor c√≥ c√πng k√≠ch th∆∞·ªõc, ƒë·∫°i di·ªán cho mask c·ªßa c√°c v·∫≠t th·ªÉ trong h√¨nh ·∫£nh. M·ªói tensor c√≥ k√≠ch th∆∞·ªõc (1, H, W), trong ƒë√≥ H l√† chi·ªÅu cao c·ªßa mask v√† W l√† chi·ªÅu r·ªông c·ªßa mask. Mask ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng ma tr·∫≠n c√°c gi√° tr·ªã s·ªë th·ª±c trong kho·∫£ng t·ª´ 0 ƒë·∫øn 1, trong ƒë√≥ 0 th∆∞·ªùng ƒë·∫°i di·ªán cho v√πng kh√¥ng c√≥ v·∫≠t th·ªÉ v√† 1 ƒë·∫°i di·ªán cho v√πng ch·ª©a v·∫≠t th·ªÉ.

orig_shape: K√≠ch th∆∞·ªõc c·ªßa h√¨nh ·∫£nh g·ªëc tr∆∞·ªõc khi ƒë∆∞·ª£c thay ƒë·ªïi k√≠ch th∆∞·ªõc ƒë·ªÉ ph√π h·ª£p v·ªõi m√¥ h√¨nh.

segments: M·ªôt danh s√°ch c√°c ƒëi·ªÉm tr√™n bi√™n c·ªßa mask, m·ªói ƒëi·ªÉm ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·∫±ng t·ªça ƒë·ªô (x, y) tr√™n ma tr·∫≠n mask.

shape: K√≠ch th∆∞·ªõc c·ªßa tensor mask, c√≥ d·∫°ng (1, H, W), trong ƒë√≥ H l√† chi·ªÅu cao c·ªßa mask v√† W l√† chi·ªÅu r·ªông c·ªßa mask.

xy v√† xyn: xy l√† danh s√°ch c√°c ƒëi·ªÉm tr√™n bi√™n c·ªßa mask, m·ªói ƒëi·ªÉm ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·∫±ng t·ªça ƒë·ªô (x, y) trong ƒë·ªãnh d·∫°ng tensor. xyn l√† danh s√°ch t·ªça ƒë·ªô c·ªßa c√°c ƒëi·ªÉm tr√™n bi√™n c·ªßa mask ƒë∆∞·ª£c chu·∫©n h√≥a trong kho·∫£ng t·ª´ 0 ƒë·∫øn 1, th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ v·∫Ω mask tr√™n h√¨nh ·∫£nh.

V·ªõi th√¥ng tin n√†y, b·∫°n c√≥ th·ªÉ truy c·∫≠p v√† x·ª≠ l√Ω mask c·ªßa c√°c v·∫≠t th·ªÉ ƒë∆∞·ª£c ph√°t hi·ªán trong h√¨nh ·∫£nh.


/////////////////////////////////

OpenCV cung c·∫•p m·ªôt s·ªë ph∆∞∆°ng ph√°p ƒë·ªÉ x√°c ƒë·ªãnh g√≥c quay c·ªßa m·ªôt v·∫≠t trong m·ªôt ·∫£nh. D∆∞·ªõi ƒë√¢y l√† m·ªôt s·ªë c√°ch th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng:

S·ª≠ d·ª•ng Hough Line Transform (Bi·∫øn ƒë·ªïi Hough cho ƒë∆∞·ªùng th·∫≥ng): ƒê√¢y l√† m·ªôt trong nh·ªØng ph∆∞∆°ng ph√°p ph·ªï bi·∫øn ƒë·ªÉ x√°c ƒë·ªãnh g√≥c quay c·ªßa v·∫≠t th·ªÉ tr√™n ·∫£nh. B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng h√†m cv2.HoughLines() ƒë·ªÉ t√¨m c√°c ƒë∆∞·ªùng th·∫≥ng trong ·∫£nh sau ƒë√≥ t√≠nh to√°n g√≥c gi·ªØa ƒë∆∞·ªùng th·∫≥ng v√† tr·ª•c t·ªça ƒë·ªô.

S·ª≠ d·ª•ng Feature Matching (Kh·ªõp ƒë·∫∑c tr∆∞ng): B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng thu·∫≠t to√°n kh·ªõp ƒë·∫∑c tr∆∞ng nh∆∞ SIFT (Scale-Invariant Feature Transform) ho·∫∑c SURF (Speeded-Up Robust Features) ƒë·ªÉ t√¨m c√°c ƒëi·ªÉm ƒë·∫∑c tr∆∞ng tr√™n v·∫≠t th·ªÉ v√† sau ƒë√≥ t√≠nh to√°n g√≥c quay t·ª´ c√°c ƒëi·ªÉm n√†y.

=>> (kh√¥ng d√πng ƒë∆∞·ª£c) S·ª≠ d·ª•ng Contour Detection (Ph√°t hi·ªán ƒë∆∞·ªùng vi·ªÅn): N·∫øu v·∫≠t th·ªÉ c√≥ h√¨nh d·∫°ng ƒë·∫∑c tr∆∞ng, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng h√†m cv2.findContours() ƒë·ªÉ t√¨m ƒë∆∞·ªùng vi·ªÅn c·ªßa v·∫≠t th·ªÉ v√† sau ƒë√≥ t√≠nh to√°n g√≥c quay d·ª±a tr√™n h∆∞·ªõng c·ªßa ƒë∆∞·ªùng vi·ªÅn.

S·ª≠ d·ª•ng Homography: N·∫øu b·∫°n c√≥ m·ªôt v·∫≠t th·ªÉ v·ªõi bi·∫øn ƒë·ªïi homography (m·ªôt lo·∫°i bi·∫øn ƒë·ªïi affine ho·∫∑c perspective), b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng h√†m cv2.findHomography() ƒë·ªÉ x√°c ƒë·ªãnh ma tr·∫≠n homography v√† sau ƒë√≥ t√≠nh to√°n g√≥c quay t·ª´ ma tr·∫≠n n√†y.

D∆∞·ªõi ƒë√¢y l√† m·ªôt v√≠ d·ª• s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p Hough Line Transform ƒë·ªÉ x√°c ƒë·ªãnh g√≥c quay c·ªßa v·∫≠t th·ªÉ trong ·∫£nh:





////////////////////////////////////


ƒê·ªÉ th√™m t√¢m c·ªßa bounding box v√†o ·∫£nh, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng th∆∞ vi·ªán OpenCV (ho·∫∑c m·ªôt th∆∞ vi·ªán x·ª≠ l√Ω ·∫£nh t∆∞∆°ng t·ª±). D∆∞·ªõi ƒë√¢y l√† c√°ch b·∫°n c√≥ th·ªÉ th·ª±c hi·ªán ƒëi·ªÅu n√†y:

Tr√≠ch xu·∫•t t·ªça ƒë·ªô t√¢m c·ªßa bounding boxes t·ª´ tensor xywh (ho·∫∑c xyxy n·∫øu b·∫°n mu·ªën).

V·∫Ω m·ªôt ƒëi·ªÉm ho·∫∑c m·ªôt ƒë∆∞·ªùng tr·ªè t·ªõi t√¢m c·ªßa bounding box tr√™n ·∫£nh g·ªëc.

D∆∞·ªõi ƒë√¢y l√† m·ªôt v√≠ d·ª• v·ªÅ c√°ch th·ª±c hi·ªán ƒëi·ªÅu n√†y:

import cv2
import numpy as np

# Load the image
image = cv2.imread('/content/drive/MyDrive/NhanDienvat/NDVat/train/images/20230919_104657_jpg.rf.f419369aed5b63d2614e2c2014ef43e5.jpg')

# Extract the 'xywh' tensor from the results (assuming a single image prediction)
xywh = results.pred[0].xywh

# Iterate through bounding boxes and draw a dot at the center
for bbox in xywh:
    x_center, y_center, width, height = bbox[:4]
    x_center = int(x_center)
    y_center = int(y_center)
    cv2.circle(image, (x_center, y_center), 5, (0, 255, 0), -1)  # Draw a green circle at the center

# Save the image with center points
cv2.imwrite('/content/center_points.jpg', image)

# Display the image (optional)
cv2.imshow('Image with Center Points', image)
cv2.waitKey(0)
cv2.destroyAllWindows()

//////ƒê·ªÉ t√≠nh to√°n g√≥c xoay c·ªßa m·ªôt ƒë∆∞·ªùng th·∫≥ng n·∫±m trong m·ªôt h√¨nh ·∫£nh, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng m·ªôt s·ªë ph∆∞∆°ng ph√°p x·ª≠ l√Ω h√¨nh ·∫£nh v√† to√°n h·ªçc. D∆∞·ªõi ƒë√¢y l√† m·ªôt c√°ch ti√™u bi·ªÉu ƒë·ªÉ th·ª±c hi·ªán ƒëi·ªÅu n√†y:

Ph√°t hi·ªán ƒë∆∞·ªùng th·∫≥ng: ƒê·∫ßu ti√™n, b·∫°n c·∫ßn ph√°t hi·ªán ƒë∆∞·ªùng th·∫≥ng trong h√¨nh ·∫£nh. OpenCV cung c·∫•p m·ªôt s·ªë ph∆∞∆°ng ph√°p ph√°t hi·ªán ƒë∆∞·ªùng th·∫≥ng, ch·∫≥ng h·∫°n nh∆∞ cv2.HoughLines ho·∫∑c cv2.HoughLinesP d·ª±a tr√™n bi·∫øn ƒë·ªïi Hough.

T√≠nh to√°n g√≥c xoay: Sau khi b·∫°n ƒë√£ c√≥ danh s√°ch c√°c ƒë∆∞·ªùng th·∫≥ng ƒë∆∞·ª£c ph√°t hi·ªán, b·∫°n c√≥ th·ªÉ t√≠nh to√°n g√≥c xoay c·ªßa m·ªói ƒë∆∞·ªùng th·∫≥ng. ƒê·ªÉ l√†m ƒëi·ªÅu n√†y, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng h√†m to√°n h·ªçc nh∆∞ atan2 (t√≠nh to√°n g√≥c d·ª±a tr√™n c√°c t·ªça ƒë·ªô c·ªßa ƒë·∫ßu m√∫t c·ªßa ƒë∆∞·ªùng th·∫≥ng) ho·∫∑c arctan (t√≠nh to√°n g√≥c d·ª±a tr√™n h·ªá s·ªë g√≥c c·ªßa ƒë∆∞·ªùng th·∫≥ng).

D∆∞·ªõi ƒë√¢y l√† m·ªôt v√≠ d·ª• c·ª• th·ªÉ s·ª≠ d·ª•ng OpenCV ƒë·ªÉ t√≠nh to√°n g√≥c xoay c·ªßa ƒë∆∞·ªùng th·∫≥ng:

python
Copy code
import cv2
import numpy as np

# ƒê·ªçc h√¨nh ·∫£nh
image = cv2.imread('image_with_line.jpg', cv2.IMREAD_GRAYSCALE)

# Ph√°t hi·ªán ƒë∆∞·ªùng th·∫≥ng b·∫±ng bi·∫øn ƒë·ªïi Hough
lines = cv2.HoughLines(image, 1, np.pi / 180, threshold=100)

# T√≠nh to√°n g√≥c xoay c·ªßa t·ª´ng ƒë∆∞·ªùng th·∫≥ng v√† chuy·ªÉn ƒë·ªïi th√†nh ƒë·ªô
for rho, theta in lines[:, 0]:
    angle = theta * 180 / np.pi
    print(f'G√≥c xoay: {angle} ƒë·ªô')

# Hi·ªÉn th·ªã h√¨nh ·∫£nh v·ªõi ƒë∆∞·ªùng th·∫≥ng ƒë√£ ph√°t hi·ªán
for rho, theta in lines[:, 0]:
    a = np.cos(theta)
    b = np.sin(theta)
    x0 = a * rho
    y0 = b * rho
    x1 = int(x0 + 1000 * (-b))
    y1 = int(y0 + 1000 * (a))
    x2 = int(x0 - 1000 * (-b))
    y2 = int(y0 - 1000 * (a))
    cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)

cv2.imshow('Image with Lines', image)
cv2.waitKey(0)
cv2.destroyAllWindows()


///////////////////////////////////////////////xac dinh huong orientation.py

# from __future__ import print_function
# from __future__ import division
import cv2 as cv
import numpy as np
import argparse
from math import atan2, cos, sin, sqrt, pi
def drawAxis(img, p_, q_, colour, scale,degree):
 p = list(p_)
 q = list(q_)
 print("diemP: ",p)
 print("diemQ: ",q)
 text1 = f"({p[0]}, {p[1]})"
 
 cv.putText(img, text1, (p[0]+30,p[1]+30), cv.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2)
 angle = atan2(p[1] - q[1], p[0] - q[0]) # angle in radians
 print("angle: ",degree)
 text2 = f"({degree})"
 cv.putText(img, text2, (p[0]+150,p[1]-30), cv.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2)

 hypotenuse = sqrt((p[1] - q[1]) * (p[1] - q[1]) + (p[0] - q[0]) * (p[0] - q[0]))
 # Here we lengthen the arrow by a factor of scale
 q[0] = p[0] - scale * hypotenuse * cos(angle)
 q[1] = p[1] - scale * hypotenuse * sin(angle)
 cv.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 5, cv.LINE_AA)
 # create the arrow hooks
 p[0] = q[0] + 9 * cos(angle + pi / 4)
 p[1] = q[1] + 9 * sin(angle + pi / 4)
 cv.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 5, cv.LINE_AA)
 p[0] = q[0] + 9 * cos(angle - pi / 4)
 p[1] = q[1] + 9 * sin(angle - pi / 4)
 cv.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 5, cv.LINE_AA)
 
def getOrientation(pts, img):
 
 sz = len(pts)
 data_pts = np.empty((sz, 2), dtype=np.float64)
 for i in range(data_pts.shape[0]):
  data_pts[i,0] = pts[i,0,0]
  data_pts[i,1] = pts[i,0,1]
 # Perform PCA analysis
 mean = np.empty((0))
 mean, eigenvectors, eigenvalues = cv.PCACompute2(data_pts, mean)
 # Store the center of the object
 cntr = (int(mean[0,0]), int(mean[0,1]))
 
 
 cv.circle(img, cntr, 3, (255, 0, 255), 2)
 p1 = (cntr[0] + 0.02 * eigenvectors[0,0] * eigenvalues[0,0], cntr[1] + 0.02 * eigenvectors[0,1] * eigenvalues[0,0])
 p2 = (cntr[0] - 0.02 * eigenvectors[1,0] * eigenvalues[1,0], cntr[1] - 0.02 * eigenvectors[1,1] * eigenvalues[1,0])

 angle = atan2(eigenvectors[0,1], eigenvectors[0,0]) # orientation in radians
 degree = angle * (180 / np.pi)

 drawAxis(img, cntr, p1, (0, 255, 0), 1,degree)
 drawAxis(img, cntr, p2, (255, 255, 0), 5,degree)

 
 return degree
parser = argparse.ArgumentParser(description='Code for Introduction to Principal Component Analysis (PCA) tutorial.\
 This program demonstrates how to use OpenCV PCA to extract the orientation of an object.')
parser.add_argument('--input', help='Path to input image.', default='pca_test1.jpg')
args = parser.parse_args()
src = cv.imread(cv.samples.findFile(args.input))


# X√°c ƒë·ªãnh c√°c t·ªça ƒë·ªô c·ªßa h√¨nh ·∫£nh b·∫°n mu·ªën c·∫Øt
# x, y, width, height = 900, 900, 1200, 1000  # V√≠ d·ª•: c·∫Øt t·ª´ (100, 100) ƒë·∫øn (300, 300)

# Th·ª±c hi·ªán ph√©p c·∫Øt
# src = image[y:y+height, x:x+width]

# Check if image is loaded successfully
if src is None:
 print('Could not open or find the image: ', args.input)
 exit(0)
# cv.imshow('src', src)
# Convert image to grayscale
gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)
# Convert image to binary
_, bw = cv.threshold(gray, 50, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)
contours, _ = cv.findContours(bw, cv.RETR_LIST, cv.CHAIN_APPROX_NONE)
for i, c in enumerate(contours):
 # Calculate the area of each contour
 area = cv.contourArea(c)
 # Ignore contours that are too small or too large
 if area < 1e2 or 1e5 < area:
  continue
 # Draw each contour only for visualisation purposes
 cv.drawContours(src, contours, i, (0, 0, 255), 2)
 # Find the orientation of each shape
 getOrientation(c, src)
 cv.imwrite('orientation_image.jpg',src)
# cv.imshow('output', src)
# cv.waitKey()


///////////////////////////////////////////////xac dinh huong orientation.py

# from __future__ import print_function
# from __future__ import division
import cv2 as cv
import numpy as np
import argparse
from math import atan2, cos, sin, sqrt, pi
def drawAxis(img, p_, q_, colour, scale,degree):
 p = list(p_)
 q = list(q_)
 print("diemP: ",p)
 print("diemQ: ",q)
 text1 = f"({p[0]}, {p[1]})"
 
 cv.putText(img, text1, (p[0]+30,p[1]+30), cv.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2)
 angle = atan2(p[1] - q[1], p[0] - q[0]) # angle in radians
 print("angle: ",degree)
 text2 = f"({degree})"
 cv.putText(img, text2, (p[0]+150,p[1]-30), cv.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2)

 hypotenuse = sqrt((p[1] - q[1]) * (p[1] - q[1]) + (p[0] - q[0]) * (p[0] - q[0]))
 # Here we lengthen the arrow by a factor of scale
 q[0] = p[0] - scale * hypotenuse * cos(angle)
 q[1] = p[1] - scale * hypotenuse * sin(angle)
 cv.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 5, cv.LINE_AA)
 # create the arrow hooks
 p[0] = q[0] + 9 * cos(angle + pi / 4)
 p[1] = q[1] + 9 * sin(angle + pi / 4)
 cv.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 5, cv.LINE_AA)
 p[0] = q[0] + 9 * cos(angle - pi / 4)
 p[1] = q[1] + 9 * sin(angle - pi / 4)
 cv.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 5, cv.LINE_AA)
 
def getOrientation(pts, img):
 
 sz = len(pts)
 data_pts = np.empty((sz, 2), dtype=np.float64)
 for i in range(data_pts.shape[0]):
  data_pts[i,0] = pts[i,0,0]
  data_pts[i,1] = pts[i,0,1]
 # Perform PCA analysis
 mean = np.empty((0))
 mean, eigenvectors, eigenvalues = cv.PCACompute2(data_pts, mean)
 # Store the center of the object
 cntr = (int(mean[0,0]), int(mean[0,1]))
 
 
 cv.circle(img, cntr, 3, (255, 0, 255), 2)
 p1 = (cntr[0] + 0.02 * eigenvectors[0,0] * eigenvalues[0,0], cntr[1] + 0.02 * eigenvectors[0,1] * eigenvalues[0,0])
 p2 = (cntr[0] - 0.02 * eigenvectors[1,0] * eigenvalues[1,0], cntr[1] - 0.02 * eigenvectors[1,1] * eigenvalues[1,0])

 angle = atan2(eigenvectors[0,1], eigenvectors[0,0]) # orientation in radians
 degree = angle * (180 / np.pi)

 drawAxis(img, cntr, p1, (0, 255, 0), 1,degree)
 drawAxis(img, cntr, p2, (255, 255, 0), 5,degree)

 
 return degree
parser = argparse.ArgumentParser(description='Code for Introduction to Principal Component Analysis (PCA) tutorial.\
 This program demonstrates how to use OpenCV PCA to extract the orientation of an object.')
parser.add_argument('--input', help='Path to input image.', default='pca_test1.jpg')
args = parser.parse_args()
src = cv.imread(cv.samples.findFile(args.input))


# X√°c ƒë·ªãnh c√°c t·ªça ƒë·ªô c·ªßa h√¨nh ·∫£nh b·∫°n mu·ªën c·∫Øt
# x, y, width, height = 900, 900, 1200, 1000  # V√≠ d·ª•: c·∫Øt t·ª´ (100, 100) ƒë·∫øn (300, 300)

# Th·ª±c hi·ªán ph√©p c·∫Øt
# src = image[y:y+height, x:x+width]

# Check if image is loaded successfully
if src is None:
 print('Could not open or find the image: ', args.input)
 exit(0)
# cv.imshow('src', src)
# Convert image to grayscale
gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)
# Convert image to binary
_, bw = cv.threshold(gray, 50, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)
contours, _ = cv.findContours(bw, cv.RETR_LIST, cv.CHAIN_APPROX_NONE)
for i, c in enumerate(contours):
 # Calculate the area of each contour
 area = cv.contourArea(c)
 # Ignore contours that are too small or too large
 if area < 1e2 or 1e5 < area:
  continue
 # Draw each contour only for visualisation purposes
 cv.drawContours(src, contours, i, (0, 0, 255), 2)
 # Find the orientation of each shape
 getOrientation(c, src)
 cv.imwrite('orientation_image.jpg',src)
# cv.imshow('output', src)
# cv.waitKey()


//////////////////////////////////////////////



# ///////////////////////////////////////////////////////////

from ultralytics import YOLO
import cv2
import numpy as np

import argparse
from math import atan2, cos, sin, sqrt, pi
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors

link = r'/content/nhandienvat/detectByYolov8/dataset_specialItems/train/images/20230922_154950_jpg.rf.a55265100fc54aa788b672e6a11b49f2.jpg'

image = cv2.imread(link)

def drawAxis(img, p_, q_, colour, scale,degree):
 p = list(p_)
 q = list(q_)
 print("diemP: ",p)
 print("diemQ: ",q)
 text1 = f"({p[0]}, {p[1]})"
 
#  cv.putText(img, text1, (p[0]+30,p[1]+30), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 1)
 angle = atan2(p[1] - q[1], p[0] - q[0]) # angle in radians
 print("angle: ",degree)
 text2 = f"{round(degree,2)} degree"
 cv2.putText(img, text2, (p[0]+10,p[1]-30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 1)

 hypotenuse = sqrt((p[1] - q[1]) * (p[1] - q[1]) + (p[0] - q[0]) * (p[0] - q[0]))
 # Here we lengthen the arrow by a factor of scale
 q[0] = p[0] - scale * hypotenuse * cos(angle)
 q[1] = p[1] - scale * hypotenuse * sin(angle)
 cv2.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 1, cv2.LINE_AA)
 # create the arrow hooks
 p[0] = q[0] + 9 * cos(angle + pi / 4)
 p[1] = q[1] + 9 * sin(angle + pi / 4)
 cv2.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 1, cv2.LINE_AA)
 p[0] = q[0] + 9 * cos(angle - pi / 4)
 p[1] = q[1] + 9 * sin(angle - pi / 4)
 cv2.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 1, cv2.LINE_AA)
 
def getOrientation(pts, img):
 sz = len(pts)
 data_pts = np.empty((sz, 2), dtype=np.float64)
 for i in range(data_pts.shape[0]):
  data_pts[i,0] = pts[i,0,0]
  data_pts[i,1] = pts[i,0,1]
 # Perform PCA analysis
 mean = np.empty((0))
 mean, eigenvectors, eigenvalues = cv2.PCACompute2(data_pts, mean)
 # Store the center of the object
 cntr = (int(mean[0,0]), int(mean[0,1]))
 
 
 cv2.circle(img, cntr, 2, (255, 0, 255), 1)
 p1 = (cntr[0] + 0.02 * eigenvectors[0,0] * eigenvalues[0,0], cntr[1] + 0.02 * eigenvectors[0,1] * eigenvalues[0,0])
 p2 = (cntr[0] - 0.02 * eigenvectors[1,0] * eigenvalues[1,0], cntr[1] - 0.02 * eigenvectors[1,1] * eigenvalues[1,0])
#  cv.circle(img, (eigenvectors[0,1], eigenvectors[0,0]), 2, (0, 0, 255), 1)
 angle = atan2(eigenvectors[0,1], eigenvectors[0,0]) # orientation in radians
 degree = angle * (180 / np.pi)

 drawAxis(img, cntr, p1, (0, 255, 0), 2,degree)
 drawAxis(img, cntr, p2, (255, 255, 0), 5,degree)
 return degree


# beta = -50  # Gi·∫£m ƒë·ªô s√°ng

# # S·ª≠ d·ª•ng h√†m cv2.convertScaleAbs ƒë·ªÉ gi·∫£m ƒë·ªô s√°ng c·ªßa ·∫£nh
# src = cv2.convertScaleAbs(image, alpha=1, beta=beta)


# # Check if image is loaded successfully
# if src is None:
# #  print('Could not open or find the image: ', args.input)
#  exit(0)
# # cv2.imshow('src', src)
# # Convert image to grayscale
# gray_picture = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)

# gray_inverted = cv2.bitwise_not(gray_picture)
# # Convert image to binary
# _, bw = cv2.threshold(gray_picture, 50, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
# contours, _ = cv2.findContours(bw, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)
# for i, c in enumerate(contours):
#  # Calculate the area of each contour
#  area = cv2.contourArea(c)
#  # Ignore contours that are too small or too large
#  if area < 1e2*3 or 1e5 < area:
#   continue
#  # Draw each contour only for visualisation purposes
#  cv2.drawContours(src, contours, i, (0, 0, 255), 2)
#  # Find the orientation of each shape
#  getOrientation(c, src)
#  cv2.imwrite('orientation_image.jpg',src)
# //////////////
# cv2.imshow('output', src)
# Assuming you have a grayscale image in the 'gray_picture' variable
# Normalize the grayscale values to be between 0 and 1

# plt.imshow(bw, cmap="gray")
# plt.title("Bitwise Gray")
# plt.axis("off")
# plt.show()

# plt.imshow(gray_inverted, cmap="gray")
# plt.title("gray_inverted Gray")
# plt.axis("off")
# plt.show()

# ///////////////////////////////////

# Load a model
model = YOLO('yolov8n-seg.pt')  # load an official model
model = YOLO(r'/content/nhandienvat/runs/segment/train/weights/best.pt')  # load a custom model

# Predict with the model
results = model(r"/content/nhandienvat/detectByYolov8/dataset_specialItems/train/images/20230922_154950_jpg.rf.a55265100fc54aa788b672e6a11b49f2.jpg", save = True)  # predict on an image


myList = []

mylistmask = []

checkitem = []
for r in results:
    # mylistmask = r.masks.xy #ss·ª≠ d·ª•ng n·∫øu d√πng ph∆∞∆°ng ph√°p t√¨m t·ªça ƒë·ªô t√¢m theo c√°c ƒëi·ªÉm masks
    # print("mask: ",r.masks[0].xy[0])
    # print("shape: ",r.masks.shape)
    # print("masks: ",r.masks)
    print("boxes: ",r.boxes)  # print the Boxes object containing the detection bounding boxes
    myList = r.boxes.xywh.tolist()
    checkitem = r.boxes.cls.tolist()
    # print(int(checkitem[2]))
print("myList: ",myList)
print("length: ",len(myList))


# print(list)
count = 0

while count < len(checkitem):
  print("count: ",count)
  if(checkitem[count] == 3.0):
    print("3")
    bBoxitem = myList[count]
    mask = np.zeros_like(image, dtype=np.uint8)
#     # ƒê·ªãnh nghƒ©a m√†u xanh m√† b·∫°n mu·ªën s·ª≠ d·ª•ng (v√≠ d·ª•: m√†u xanh l√° c√¢y)
#     green_color = ( 255,255, 0)  # Xanh l√° c√¢y: (B, G, R)

# # G√°n gi√° tr·ªã m√†u xanh cho m·∫∑t n·∫°
#     mask[:, :] = green_color

    a = (bBoxitem[0] - bBoxitem[2]/2, bBoxitem[1] - bBoxitem[3]/2)
    b = (bBoxitem[0] + bBoxitem[2]/2, bBoxitem[1] - bBoxitem[3]/2)
    c = (bBoxitem[0] + bBoxitem[2]/2, bBoxitem[1] + bBoxitem[3]/2)
    d = (bBoxitem[0] - bBoxitem[2]/2, bBoxitem[1] + bBoxitem[3]/2)

    points = np.array([a, b,c ,d], dtype=np.int32)
    cv2.fillPoly(mask, [points], (255, 255, 255))
    src = cv2.bitwise_and(image, mask)
    beta = -50  # Gi·∫£m ƒë·ªô s√°ng
        # S·ª≠ d·ª•ng h√†m cv2.convertScaleAbs ƒë·ªÉ gi·∫£m ƒë·ªô s√°ng c·ªßa ·∫£nh
    result = cv2.convertScaleAbs(src, alpha=1, beta=beta)


    # Check if image is loaded successfully
    if result is None:
    #  print('Could not open or find the image: ', args.input)
        exit(0)
    # cv2.imshow('src', src)
    # Convert image to grayscale
    gray_picture = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)

    gray_inverted = cv2.bitwise_not(gray_picture)
    # Convert image to binary
    _, bw = cv2.threshold(gray_picture, 50, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
    # cv2.imwrite('bibi.jpg', bw)
    
    contours, _ = cv2.findContours(bw, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)
    for i, c in enumerate(contours):
    # Calculate the area of each contour
      area = cv2.contourArea(c)
    # Ignore contours that are too small or too large
      if area < 1e2*3 or 1e5 < area:
        continue
    # Draw each contour only for visualisation purposes
        cv2.drawContours(result, contours, i, (0, 0, 255), 2)
    # Find the orientation of each shape
      kq =  getOrientation(c, result)
      print("kq: ", kq)
  if checkitem[count] == 4.0:

    list = myList[count]
    point = (list[0],list[1])
    print("point :",point)
    color = (0, 255, 0)
    # K√≠ch th∆∞·ªõc c·ªßa ƒëi·ªÉm
    thickness = -1  # ƒê·∫∑t -1 ƒë·ªÉ v·∫Ω m·ªôt ƒëi·ªÉm ƒë·∫ßy ƒë·ªß
    # V·∫Ω ƒëi·ªÉm tr√™n h√¨nh ·∫£nh
    cv2.circle(image, (int(list[0]),int(list[1])), 3, (0, 0, 255), thickness) #ch·∫•m ƒëi·ªÉm v√†o ·∫£nh ·ªü t·ªça ƒë·ªô t√¢m c·ªßa bounding box c·ªßa l·ªó t√¢m
    # in t·ªça ƒë·ªô c·ªßa t√¢m
    text = f"({int(list[0])}, {int(list[1])})"
    cv2.putText(image, text, (int(list[0])+30,int(list[1])+30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
    cv2.line(image, (int(list[0]),int(list[1])), (int(list[0]) + 50, int(list[1])), (0, 0, 255), 2)  # V·∫Ω tr·ª•c X (m√†u ƒë·ªè)
    cv2.line(image, (int(list[0]),int(list[1])), (int(list[0]), int(list[1]) + 50), (0, 255, 0), 2)  # V·∫Ω tr·ª•c Y (m√†u xanh l√°)
  count = count + 1
# print("list masks: ",mylistmask.tolist()[0])



# ///////////////////C√°ch l·∫•y t√¢m t·ª´ c√°c ƒëi·ªÉm masks/////////////
# count = 0
# while count < len(mylistmask):
#   if checkitem[count] == 4.0:
#     print("count: ", count)
#     print(mylistmask[count].tolist())
#     listitem = mylistmask[count].tolist()
#     count2 = 0
#     totalx= 0
#     totaly = 0
#     x = 0
#     y = 0
    
#     while count2 < len(listitem):
#       print(listitem[count2])
#       coodinate = listitem[count2]
#       totalx = totalx + coodinate[0]
#       totaly = totaly + coodinate[1]
#       # cv2.circle(image, (int(coodinate[0]),int(coodinate[1])), 3, color, thickness)
#       cv2.drawMarker(image, (int(coodinate[0]),int(coodinate[1])), color, markerType=cv2.MARKER_STAR, markerSize=2)
#       count2 = count2 + 1
#     x = totalx / len(listitem)
#     y = totaly / len(listitem)
#     cv2.drawMarker(image, (int(x),int(y)), color, markerType=cv2.MARKER_STAR, markerSize=2)
#   count = count + 1


cv2.imwrite('output_image2.jpg', image)
cv2.imwrite('output_image3.jpg', result)


#K·∫øt lu·∫≠n r·∫±ng l·∫•y t√¢m c·ªßa bounding box c·ªßa l·ªó t√¢m chu·∫©n h∆°n c√°ch l·∫•y t√¢m t·ª´ c√°c ƒëi·ªÉm masks c·ªßa l·ªó t√¢m 


////////////////tim tam

Th·ª±c hi·ªán ti·ªÅn x·ª≠ l√≠ l·∫ßn l∆∞·ª£t b·∫±ng c√°c thu·∫≠t to√°n: Constrast Stretch ƒë·ªÉ
chi·ªÅu ch·ªânh l·∫°i ƒë·ªô t∆∞∆°ng ph·∫£n, Threshold ƒë·ªÉ c√≥ ƒë∆∞·ª£c ·∫£nh binary, t√¨m 
c·∫°nh b·∫±ng Canny Edge, v√† nh·ªØng thu·∫≠t to√°n nh∆∞ dilation, find 
Contours.
Trong ƒë√≥, thu·∫≠t to√°n Constrast Strect, Threshold, find Contours ƒë√£ 
ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p ·ªü c√°c ph·∫ßn b√™n tr√™n
Thu·∫≠t to√°n Canny Edge c√≥ th·ªÉ xem th√™m ·ªü ph·∫ßn ph·ª• l·ª•c 1.3
Thu·∫≠t to√°n Dilation:
- ƒê√¢y l√† thu·∫≠t to√°n b·ªï tr·ª£ th√™m cho thu·∫≠t to√°n Canny Edges nh·∫±m 
l√†m tƒÉng ch·∫•t l∆∞·ª£ng c√°c c·∫°nh tr∆∞·ªõc khi ƒë∆∞a v√†o thu·∫≠t to√°n Find 
Contours. 
- Dilation l√† m·ªôt trong nh·ªØng ph√©p bi·∫øn ƒë·ªïi thao t√°c t√°c ƒë·ªông ƒë·∫øn 
h√¨nh th√°i c·ªßa v·∫≠t th·ªÉ trong ·∫£nh. Th√¥ng qua 1 Kernel c√≥ k√≠ch th∆∞·ªõc 
ƒë∆∞·ª£c ch·ªânh ƒë·ªãnh t·ª´ ban ƒë·∫ßu. N√≥ s·∫Ω th·ª±c hi·ªán t√¨m pixel c√≥ gi√° tr·ªã
l·ªõn nh·∫•t sau ƒë√≥ g√°n to√†n b·ªô c√°c pixel n·∫±m trong v√πng Kernel ƒë√≥ 
b·∫±ng ch√≠nh gi√° tr·ªã l·ªõn nh·∫•t ƒë√≥.
- ƒêi·ªÅu n√†y ƒë·ªìng nghƒ©a v·ªõi vi·ªác, n√≥ s·∫Ω gi√∫p cho h√¨nh d·∫°ng c·ªßa v·∫≠t 
th·ªÉ, c·ªßa c·∫°nh n√≥ s·∫Ω ƒë∆∞·ª£c ph√¨nh to ra h∆°n v√† c√≥ kh·∫£ nƒÉng li√™n k·∫øt 
ƒë∆∞·ª£c nh·ªØng c·∫°nh r·ªùi r·∫°c ·ªü m·ªôt m·ª©c ƒë·ªô n√†o ƒë√≥.
- Thu·∫≠t to√°n n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng nh·∫±m m·ª•c ƒë√≠ch li√™n k·∫øt l·∫°i c√°c c·∫°nh 
thu ƒë∆∞·ª£c t·ª´ thu·∫≠t to√°n Canny ƒë·ªÉ ƒë·∫£m b·∫£o r·∫±ng s·∫Ω kh√¥ng c√≥ c·∫°nh 
n√†o b·ªã ƒë·ª©t kh√∫c gi·ªØa ch·ª´ng.

Thu·∫≠t to√°n t√¨m t√¢m c·ªßa con h√†ng
Sau khi tr√≠ch xu·∫•t ƒë∆∞·ª£c RoI d·ª±a tr√™n k·∫øt qu·∫£ t·ª´ YOLO, ta th·ª±c hi·ªán √°p 
d·ª•ng 1 s·ªë thu·∫≠t to√°n x·ª≠ l√≠ ·∫£nh nh·∫±m m·ª•c ƒë√≠ch thu ƒë∆∞·ª£c ·∫£nh binary m√† 
ch·ªâ ch·ª©a c√°c c·∫°nh b√™n trong

ƒê·ªÉ th·ª±c hi·ªán ƒë∆∞·ª£c ƒëi·ªÅu ƒë√≥, l·∫ßn l∆∞·ª£t ƒë∆∞a RoI qua c√°c thu·∫≠t to√°n theo th·ª©
t·ª± Contrast stretching, thresholding, canny edge detection, dilation
Sau khi c√≥ ƒë∆∞·ª£c ·∫£nh ƒë·∫ßu ra mong mu·ªën, ta th·ª±c hi·ªán t√¨m contour c·ªßa 
RoI, tuy nhi√™n v√¨ s·ªë l∆∞·ª£ng contour tr·∫£ v·ªÅ s·∫Ω l·ªõn h∆°n 1. V√¨ th·∫ø m√† ta s·∫Ω
c√≥ th√™m 1 v√†i b∆∞·ªõc l·ªçc b·ªõt c√°c contour kh√¥ng ph√π h·ª£p.
Sau khi x·ª≠ l√≠ xong v√† thu ƒë∆∞·ª£c contour t·ªëi ∆∞u, ta th·ª±c hi·ªán t√¨m ƒë∆∞·ªùng 
tr√≤n c√≥ b√°n k√≠nh nh·ªè nh·∫•t m√† ch·ª©a t·∫•t c·∫£ c√°c ƒëi·ªÉm trong contour t·ªëi ∆∞u, 
sau ƒë√≥ thu ƒë∆∞·ª£c t√¢m c·ªßa ƒë∆∞·ªùng tr√≤n. ƒê·ªìng th·ªùi, ta c≈©ng th·ª±c hi·ªán t√≠nh 
to√°n t√¢m c·ªßa contour v√† k·∫øt h·ª£p t√≠nh trung b√¨nh v·ªõi t√¢m c·ªßa ƒë∆∞·ªùng tr√≤n 
thu ƒë∆∞·ª£c l√∫c tr∆∞·ªõc ƒë·ªÉ tr·∫£ v·ªÅ gi√° tr·ªã t·ªça ƒë·ªô pixel c·ªßa t√¢m v·∫≠t h√†ng t·ªët 
nh·∫•t
///////////////////////////////////
 T√¨m g√≥c t·ªëi ∆∞u
 S·ª≠ d·ª•ng Template Matching cho vi·ªác tinh ch·ªânh l·∫°i g√≥c c·ªßa con 
h√†ng
Ti·∫øn h√†nh t·∫°o Template tr∆∞·ªõc:

Sau khi c√≥ ƒë∆∞·ª£c template tr√™n, ta s·∫Ω ti·∫øn h√†nh xoay template m·ªôt gi√° tr·ªã
b·∫±ng Œ± + g√≥c ƒë·ªÅ xu·∫•t (Œ± s·∫Ω n·∫±m trong kho·∫£ng t·ª´ -50 ƒë·∫øn 50, gi√° tr·ªã n√†y c√≥ th·ªÉ thay ƒë·ªïi t√πy thu·ªôc v√†o vi·ªác m√¥ h√¨nh Segmentation c√≥ c·∫ßn ph·∫£i 
ƒë∆∞·ª£c t·ªëi ∆∞u nhi·ªÅu hay kh√¥ng).

Sau ƒë√≥ ta s·∫Ω ti·∫øn h√†nh matching template ƒë√£ ƒë∆∞·ª£c xoay ·ªü tr√™n v·ªõi m·ªôt 
v√πng roi ƒë√£ ƒë∆∞·ª£c chuy·ªÉn sang d·∫°ng binary, v√† ta l·ª±a ch·ªçn c√≥ gi√° tr·ªã g√≥c 
t·ªëi ∆∞u h∆°n d·ª±a tr√™n ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa template v√† RoI

ÔÉò T·ªëi ∆∞u thu·∫≠t to√°n
√ù t∆∞·ªüng tri·ªÉn khai:
- H·∫°n ch·∫ø c·ªßa thu·∫≠t to√°n hi·ªán t·∫°i l√† s·ª± l·∫∑p l·∫°i vi·ªác t√≠nh to√°n m·∫∑c d√π 
c√≥ th·ªÉ g√≥c ƒë·ªÅ xu·∫•t ƒë√£ l√† g√≥c t·ªëi ∆∞u
- Gi·∫£ ƒë·ªãnh r·∫±ng, n·∫øu g√≥c ƒë·ªÅ xu·∫•t c√≥ th·ªÉ ƒë∆∞·ª£c tinh ch·ªânh v√† cho k·∫øt 
qu·∫£ t·ªët h∆°n, t·ª©c l√† gi√° tr·ªã t∆∞∆°ng ƒë·ªìng gi·ªØa Template v√† RoI s·∫Ω cao 
h∆°n. ƒêi·ªÅu ƒë√≥ ƒë·ªìng nghƒ©a v·ªõi vi·ªác, n·∫øu ch√∫ng ta ki·ªÉm tra xem li·ªáu 
v·ªõi g√≥c tinh ch·ªânh ƒë·∫ßu ti√™n gi√° tr·ªã t∆∞∆°ng ƒë·ªìng (Similarity score) 
tr·∫£ v·ªÅ c√≥ cao h∆°n so v·ªõi ƒë·ªô t∆∞∆°ng ƒë·ªìng khi t√≠nh v·ªõi g√≥c ƒë·ªÅ xu·∫•t t·ª´
Segmentation, th√¨ ta s·∫Ω cho ph√©p vi·ªác tinh ch·ªânh ti·∫øp t·ª•c x·∫£y ra.
- Tuy nhi√™n, n·∫øu khi ƒë·∫øn 1 ƒë·ªô tinh ch·ªânh n√†o ƒë√≥, gi√° tr·ªã similarity tr·∫£
v·ªÅ th·∫•p h∆°n so v·ªõi gi√° tr·ªã similarity c·ªßa g√≥c tinh ch·ªânh tr∆∞·ªõc ƒë√≥. 
Vi·ªác tinh ch·ªânh s·∫Ω b·ªã d·ª´ng ngay l·∫≠p t·ª©c.
- ƒê·ªÉ c√¢n b·∫±ng vi·ªác sai l·ªách theo chi·ªÅu √¢m ho·∫∑c d∆∞∆°ng, ta s·∫Ω th·ª±c 
hi·ªán t√≠nh to√°n c√πng l√∫c ƒë·ªô tinh ch·ªânh theo chi·ªÅu d∆∞∆°ng v√† ƒë·ªô tinh 
ch·ªânh theo chi·ªÅu √¢m. V√≤ng l·∫∑p s·∫Ω k·∫øt th√∫c khi c·∫£ 2 b√™n tinh ch·ªânh 
√¢m v√† d∆∞∆°ng ƒë·ªÅu kh√¥ng th·ªÉ tinh ch·ªânh ƒë∆∞·ª£c g√≥c ƒë·ªÅ xu·∫•t sang g√≥c 
t·ªëi ∆∞u ƒë∆∞·ª£c n·ªØa
 Sau ƒë√≥ ta s·∫Ω th·ª±c hi·ªán so s√°nh c√°c k·∫øt qu·∫£ cu·ªëi c√πng c·ªßa c·∫£ 2 b√™n 
so v·ªõi similarity score c·ªßa g√≥c ƒë·ªÅ xu·∫•t t·ª´ Segmentation ƒë·ªÉ ch·ªçn 
ra g√≥c t·ªëi ∆∞u nh·∫•t cho v·∫≠t th·ªÉ.

L·ª±a ch·ªçn th·ª© t·ª± g·∫Øp con h√†ng
ÔÅ∂ T·ªïng qu√°t
ƒê√¢y l√† b∆∞·ªõc ƒë∆∞·ª£c th·ª±c hi·ªán sau khi ƒë√£ qua thu·∫≠t to√°n x·ª≠ l√≠ ·∫£nh v√† ƒë√£ cho 
ra ƒë∆∞·ª£c t·ªça ƒë·ªô c√°c v·∫≠t h√†ng nh·∫≠n di·ªán ƒë∆∞·ª£c.
·ªû b∆∞·ªõc n√†y, ta s·∫Ω th·ª±c hi·ªán x√°c ƒë·ªãnh m·ª©c ƒë·ªô kh·∫£ thi c√≥ th·ªÉ g·∫Øp ƒë∆∞·ª£c c·ªßa 
v·∫≠t h√†ng, ƒë√¢y l√† b∆∞·ªõc ƒë∆∞·ª£c d√πng ƒë·ªÉ t·ªëi ∆∞u hi·ªáu su·∫•t v√† gi·∫£m thi·ªÉu m·ª©c ƒë·ªô
r·ªßi ro khi g·∫Øp h√†ng.
ÔÅ∂ V·∫•n ƒë·ªÅ v√† gi·∫£i ph√°p
V·∫•n ƒë·ªÅ: 
- Trong ph·∫°m vi c·ªßa ƒë·ªì √°n, c√°c v·∫≠t h√†ng s·∫Ω ·ªü v·ªã tr√≠ ng·∫´u nhi√™n v√† kh√¥ng 
bi·∫øt tr∆∞·ªõc ƒë∆∞·ª£c v·ªã tr√≠ c·ª• th·ªÉ. Ngo·∫°i tr·ª´ c√°c tr∆∞·ªùng h·ª£p c√°c v·∫≠t h√†ng 
ch·ªìng ch√©o nhau, n·∫±m nghi√™ng theo chi·ªÅu ƒë·ª©ng ho·∫∑c ngang v√† n·∫±m √∫p 
s·∫Ω b·ªã lo·∫°i b·ªè v√† kh√¥ng th·ª±c hi·ªán g·∫Øp, c√≤n l·∫°i t·∫•t c·∫£ c√°c con h√†ng n·∫±m 
ng·ª≠a d√π l√† g·∫ßn nhau ƒë·∫øn d√≠nh v√†o nhau th√¨ v·∫´n s·∫Ω ƒë∆∞·ª£c g·∫Øp ƒë·ªÉ ƒë·∫£m 
b·∫£o s·ªë l∆∞·ª£ng t√≠nh theo ph√∫t.
- T·ª´ ƒë√≥ s·∫Ω ph√°t sinh ra v·∫•n ƒë·ªÅ l√† khi Robot th·ª±c hi·ªán g·∫Øp v·∫≠t, c√≥ kh·∫£
nƒÉng s·∫Ω g√¢y t√°c ƒë·ªông nh·∫π ƒë·∫øn v·∫≠t h√†ng ƒëang g·∫Øp. N·∫øu v·∫≠t h√†ng ƒë√≥ n·∫±m 
ƒë·ªôc l·∫≠p kh√¥ng g·∫ßn c√°c v·∫≠t h√†ng kh√°c, ƒëi·ªÅu n√†y s·∫Ω kh√¥ng ph·∫£i ƒë√°ng lo 
ng·∫°i. Nh∆∞ng n·∫øu v·∫≠t h√†ng ƒëang g·∫Øp c√≥ c√°c v·∫≠t h√†ng kh√°c g·∫ßn ƒë√≥ th·∫≠m 
ch√≠ l√† d√≠nh v√†o, vi·ªác t√°c ƒë·ªông nh∆∞ v·∫≠y c√≥ kh·∫£ nƒÉng l√†m d·ªãch chuy·ªÉn v·ªã
tr√≠ c·ªßa c√°c v·∫≠t h√†ng b√™n c·∫°nh.
- Trong khi ƒë√≥, ·ª©ng v·ªõi m·ªói l·∫ßn nh·∫≠n di·ªán c√°c v·∫≠t h√†ng, th√¨ Robot s·∫Ω
nh·∫≠n to√†n b·ªô c√°c t·ªça ƒë·ªô c·ªßa v·∫≠t h√†ng c√≥ th·ªÉ g·∫Øp ƒë∆∞·ª£c. Vi·ªác l√†m thay 
ƒë·ªïi ƒëi t·ªça ƒë·ªô c·ªßa v·∫≠t h√†ng b√™n c·∫°nh s·∫Ω t√°c ƒë·ªông kh√¥ng h·ªÅ nh·ªè ƒë·∫øn kh·∫£
nƒÉng g·∫Øp v·∫≠t sau n√†y c·ªßa Robot.
- Ch√≠nh v√¨ th·∫ø m√† m·ªôt ƒë·ªô ƒëo m·ª©c ƒë·ªô kh·∫£ thi ƒë∆∞·ª£c √°p d·ª•ng ƒë·ªÉ x√°c ƒë·ªãnh 
li·ªáu v·∫≠t h√†ng ƒë√≥ c√≥ bao nhi√™u ph·∫ßn trƒÉm l√† kh·∫£ thi ƒë·ªÉ g·∫Øp ƒë∆∞·ª£c m√† √≠t 
g√¢y ·∫£nh h∆∞·ªüng ƒë·∫øn c√°c v·∫≠t h√†ng xung quanh.
√ù t∆∞·ªüng:
- Ch√∫ng ta s·∫Ω t·∫≠n d·ª•ng 2 thu·∫≠t to√°n x·ª≠ l√≠ ·∫£nh l√† Contrast stretch v√† 
thresholding ƒë·ªÉ th·ª±c hi·ªán l·∫•y ·∫£nh binary c·ªßa c·∫£ Template v√† RoI.
Tuy nhi√™n, ƒë·ªëi v·ªõi b∆∞·ªõc n√†y, ta s·∫Ω kh√¥ng c·∫Øt RoI b·∫±ng v·ªõi Bounding 
Box t·ª´ YOLO m√† s·∫Ω n·ªõi r·ªông RoI ra l·ªõn h∆°n (Padding 100 pixel ch·ªó
m·ªói ph√≠a c·ªßa RoI) nh·∫±m m·ª•c ƒë√≠ch c√≥ th·ªÉ bao tr·ªçn c√°c khu v·ª±c xung 
quanh c·ªßa v·∫≠t h√†ng h∆°n.
- Sau ƒë√≥ ta th·ª±c hi·ªán t√≠nh t·ªïng s·ªë pixel m√† m·ªói pixel ƒë∆∞·ª£c coi l√† thu·ªôc 
v·∫≠t h√†ng, trong tr∆∞·ªùng h·ª£p c·ª• th·ªÉ nh∆∞ hi·ªán t·∫°i, pixel n√†o c√≥ gi√° tr·ªã b·∫±ng 
0 th√¨ ƒë∆∞·ª£c xem nh∆∞ thu·ªôc v·∫≠t h√†ng. Ta s·∫Ω t√≠nh t·ªïng s·ªë l∆∞·ª£ng pixel ƒë√≥ 
l·∫°i v√† xem n√≥ nh∆∞ gi√° tr·ªã ƒë·∫°i di·ªán v·ªÅ ƒë·ªô ƒë·∫≠m ƒë·∫∑c c·ªßa Template hay RoI 
(g·ªçi l√† Intensity).
- Nh∆∞ tr√™n h√¨nh 3.27, ƒë·ªëi v·ªõi c√°c con h√†ng b·ªã bao quanh b·ªüi c√°c con 
h√†ng kh√°c, th√¨ v√πng pixel b·∫±ng 0 s·∫Ω nhi·ªÅu h∆°n so v·ªõi Template
- Ti·∫øp theo ta th·ª±c hi·ªán t√≠nh to√°n m·ª©c ƒë·ªô kh·∫£ thi c√≥ th·ªÉ g·∫Øp ƒë∆∞·ª£c theo 
c√¥ng th·ª©c:
ùëÉ =
œÉ(ùëá)
œÉ(ùëÖùëúùêº)
‚àó 100
ÔÇß Trong ƒë√≥:
ÔÇ∑ P l√† gi√° tr·ªã m·ª©c ƒë·ªô kh·∫£ thi c√≥ th·ªÉ g·∫Øp ƒë∆∞·ª£c
ÔÇ∑ ùúé(ùëá) l√† Intensity c·ªßa Template
ÔÇ∑ ùúé(ùëÖùëúùêº) l√† Intensity c·ªßa RoI
- B·∫±ng c√°ch n√†y, khi RoI c√≥ ch·ª©a c√°c v·∫≠t h√†ng k·∫ø b√™n, th√¨ s·∫Ω c√≥ c√°c pixel 
thu·ªôc v·∫≠t h√†ng ƒë√≥ n·∫±m trong RoI, ƒëi·ªÅu n√†y s·∫Ω d·∫´n ƒë·∫øn Intensity c·ªßa 
RoI s·∫Ω ƒë∆∞·ª£c tƒÉng l√™n cao h∆°n v√† P s·∫Ω gi·∫£m xu·ªëng.
- Sau ƒë√≥ ta th·ª±c hi·ªán s·∫Øp x·∫øp l·∫°i theo m·ª©c ƒë·ªô gi·∫£m d·∫ßn gi√° tr·ªã P t∆∞∆°ng 
·ª©ng v·ªõi m·ª©c ƒë·ªô ∆∞u ti√™n tƒÉng d·∫ßn v√† v·ªõi c√°c con h√†ng c√≥ gi√° tr·ªã P th·∫•p 
h∆°n ng∆∞·ª°ng quy ƒë·ªãnh s·∫Ω ƒë∆∞·ª£c b·ªè qua v√† kh√¥ng g·∫Øp ƒë·ªÉ tr√°nh tr∆∞·ªùng 
h·ª£p v·∫≠t ƒë√≥ b·ªã x√™ d·ªãch ƒëi qu√° nhi·ªÅu b·ªüi nh·ªØng con h√†ng kh√°c l√∫c g·∫Øp
- Tuy nhi√™n, ƒë·ªô ƒëo n√†y n√≥ kh√¥ng ho√†n to√†n th·∫≠t s·ª± t√¨m ƒë∆∞·ª£c v·∫≠t h√†ng 
n√†o ∆∞u ti√™n nh·∫•t, v√¨ c∆° b·∫£n t·ª´ b∆∞·ªõc t√≠nh Intensity th√¨ n√≥ ƒë√£ ph·ª• thu·ªôc 
r·∫•t nhi·ªÅu v√†o ch·∫•t l∆∞·ª£ng c·ªßa ƒë·∫ßu ra thu·∫≠t to√°n x·ª≠ l√≠ ·∫£nh, gi·∫£ s·ª≠ trong 
tr∆∞·ªùng h·ª£p ƒë·∫ßu ra n√≥ b·ªã nhi·ªÖu b·ªüi Background, th√¨ Intensity n√≥ kh√¥ng 
ho√†n to√†n ƒë·∫°i di·ªán ƒë∆∞·ª£c cho ·∫£nh. Ngo√†i ra, v·∫≠t h√†ng trong RoI c≈©ng 
ch∆∞a ho√†n to√†n s·∫Ω gi·ªëng v·ªõi Template v√¨ s·∫Ω b·ªã kh√°c g√≥c ch·ª•p n·∫øu n·∫±m 
xa t√¢m Camera.
- Ch√≠nh v√¨ th·∫ø m√† ƒë·ªô ƒëo n√†y ch·ªâ th·∫≠t s·ª± ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ gi·∫£m b·ªõt kh·∫£
nƒÉng Robot s·∫Ω t√°c ƒë·ªông v√†o nh·ªØng v·∫≠t h√†ng d√≠nh v·ªõi nhau l√†m sai l·ªách 
ƒëi t·ªça ƒë·ªô th·ª±c t·∫ø
 C√°c s·ªë ƒë∆∞·ª£c ƒë√°nh d·∫•u cho t·ª´ng v·∫≠t h√†ng n·∫±m ng·ª≠a thu ƒë∆∞·ª£c ƒë·∫°i di·ªán 
cho th·ª© t·ª± m√† Robot s·∫Ω g·∫Øp, c√≥ th·ªÉ th·∫•y v·∫≠t h√†ng s·ªë 7, 8, 9, 10 l√† c√°c 
v·∫≠t h√†ng ƒë∆∞·ª£c g·∫Øp sau c√πng v√¨ c√≥ hi·ªán t∆∞·ª£ng d√≠nh v·ªõi nhau.
- ƒê·ªëi v·ªõi ƒë·ªô ƒëo n√†y, ta ch·ªâ th·∫≠t s·ª± quan t√¢m ƒë·∫øn c√°c v·∫≠t h√†ng d√≠nh v√†o 
nhau, c√≤n nh·ªØng v·∫≠t h√†ng r·ªùi r·∫°c ch√∫ng ta s·∫Ω kh√¥ng quan t√¢m vi·ªác n√≥ 
c√≥ b·ªã x√™ d·ªãch trong qu√° tr√¨nh g·∫Øp hay kh√¥ng.


////////////////Pseudo code lay goc toi uu
- H·∫°n ch·∫ø c·ªßa thu·∫≠t to√°n hi·ªán t·∫°i l√† s·ª± l·∫∑p l·∫°i vi·ªác t√≠nh to√°n m·∫∑c d√π 
c√≥ th·ªÉ g√≥c ƒë·ªÅ xu·∫•t ƒë√£ l√† g√≥c t·ªëi ∆∞u
- Gi·∫£ ƒë·ªãnh r·∫±ng, n·∫øu g√≥c ƒë·ªÅ xu·∫•t c√≥ th·ªÉ ƒë∆∞·ª£c tinh ch·ªânh v√† cho k·∫øt 
qu·∫£ t·ªët h∆°n, t·ª©c l√† gi√° tr·ªã t∆∞∆°ng ƒë·ªìng gi·ªØa Template v√† RoI s·∫Ω cao 
h∆°n. ƒêi·ªÅu ƒë√≥ ƒë·ªìng nghƒ©a v·ªõi vi·ªác, n·∫øu ch√∫ng ta ki·ªÉm tra xem li·ªáu 
v·ªõi g√≥c tinh ch·ªânh ƒë·∫ßu ti√™n gi√° tr·ªã t∆∞∆°ng ƒë·ªìng (Similarity score) 
tr·∫£ v·ªÅ c√≥ cao h∆°n so v·ªõi ƒë·ªô t∆∞∆°ng ƒë·ªìng khi t√≠nh v·ªõi g√≥c ƒë·ªÅ xu·∫•t t·ª´
Segmentation, th√¨ ta s·∫Ω cho ph√©p vi·ªác tinh ch·ªânh ti·∫øp t·ª•c x·∫£y ra.
- Tuy nhi√™n, n·∫øu khi ƒë·∫øn 1 ƒë·ªô tinh ch·ªânh n√†o ƒë√≥, gi√° tr·ªã similarity tr·∫£
v·ªÅ th·∫•p h∆°n so v·ªõi gi√° tr·ªã similarity c·ªßa g√≥c tinh ch·ªânh tr∆∞·ªõc ƒë√≥. 
Vi·ªác tinh ch·ªânh s·∫Ω b·ªã d·ª´ng ngay l·∫≠p t·ª©c.
- ƒê·ªÉ c√¢n b·∫±ng vi·ªác sai l·ªách theo chi·ªÅu √¢m ho·∫∑c d∆∞∆°ng, ta s·∫Ω th·ª±c 
hi·ªán t√≠nh to√°n c√πng l√∫c ƒë·ªô tinh ch·ªânh theo chi·ªÅu d∆∞∆°ng v√† ƒë·ªô tinh 
ch·ªânh theo chi·ªÅu √¢m. V√≤ng l·∫∑p s·∫Ω k·∫øt th√∫c khi c·∫£ 2 b√™n tinh ch·ªânh 
√¢m v√† d∆∞∆°ng ƒë·ªÅu kh√¥ng th·ªÉ tinh ch·ªânh ƒë∆∞·ª£c g√≥c ƒë·ªÅ xu·∫•t sang g√≥c 
t·ªëi ∆∞u ƒë∆∞·ª£c n·ªØa

- Sau ƒë√≥ ta s·∫Ω th·ª±c hi·ªán so s√°nh c√°c k·∫øt qu·∫£ cu·ªëi c√πng c·ªßa c·∫£ 2 b√™n 
so v·ªõi similarity score c·ªßa g√≥c ƒë·ªÅ xu·∫•t t·ª´ Segmentation ƒë·ªÉ ch·ªçn 
ra g√≥c t·ªëi ∆∞u nh·∫•t cho v·∫≠t th·ªÉ.

Input
    source image, TemplateImage
    Box, angle
Output
    Point( with maximal similarity score)

Function matchTemplate(sourceImage, templateImage, box, angle)
    SET x,y,wR,hR <- box
    CAll rotateTemplate(TemplateImage, angle) RETURN rotatedTemplate, mask, wT, hT
    SET RoI <- ùë†ùëúùë¢ùëüùëêùëíùêºùëöùëéùëîùëí ùë¶ ‚à∂ ùë¶ + ‚ÑéùëÖ, ùë• ‚à∂ ùë• + ùë§ùëÖ 
    CAùë≥ùë≥ ùëùùëéùëëùëëùëñùëõùëîùëÖùëúùêº(ùëÖùëúùêº, ùëüùëúùë°ùëéùë°ùëíùëëùëáùëíùëöùëùùëôùëéùë°ùëí) ùëπùë¨ùëªùëºùëπùëµ ùëùùëéùëëùëëùëíùëëùëÖùëúùêº
    ùë∫ùë¨ùëª ùëêùëúùëüùëüùëíùëôùëéùë°ùëñùëúùëõùëÄùëéùëù ‚Üê ùëéùëüùëüùëéùë¶ [ùëùùëéùëëùëëùëíùëëùëÖùëúùêº. ùëÜ‚Ñéùëéùëùùëí ]

    ùë≠ùë∂ùëπ ùëñ ùë≠ùëπùë∂ùë¥ ùëùùëéùëëùëëùëíùëëùëÖùëúùêº. ùêªùëíùëñùëî‚Ñéùë°
        ùë≠ùë∂ùëπ ùëó ùë≠ùëπùë∂ùë¥ ùëùùëéùëëùëëùëíùëëùëÖùëúùêº. ùëäùëñùëëùë°‚Ñé
            ùë∫ùë¨ùëª ùë†ùë¢ùëèùëÖùëúùêº ‚Üê ùëùùëéùëëùëëùëíùëëùëÖùëúùêº[ ùëñ ‚à∂ ùëñ + ‚Ñéùëá,ùëó ‚à∂ ùëó + ùë§ùëá ]
            ùë™ùë®ùë≥ùë≥ ùëêùëúùëöùëùùë¢ùë°ùëíùëÜùëñùëöùëñùëôùëéùëüùëñùë°ùë¶(ùë†ùë¢ùëèùëÖùëúùêº, ùëüùëúùë°ùëéùë°ùëíùëëùëáùëíùëöùëùùëôùëéùë°ùëí) ùëπùë¨ùëªùëºùëπùëµ ùëêùëúùëüùëüùëíùëôùëéùë°ùëñùëúùëõùëÜùëêùëúùëüùëí
            ùë®ùë´ùë´ ùëêùëúùëüùëüùëíùëôùëéùë°ùëñùëúùëõùëÜùëêùëúùëüùëí ‚Üí ùëêùëúùëüùëüùëíùëôùëéùë°ùëñùëúùëõùëÄùëéùëù ùëñ,ùëó 
        ùë¨ùëµùë´ùë≠ùë∂ùëπ
    ùë¨ùëµùë´ùë≠ùë∂R
    Sùë¨ùëª ùëÉùëúùëñùëõùë° ‚Üê ùëöùëéùë•ùëôùëúùëê(ùëêùëúùëüùëüùëíùëôùëéùë°ùëñùëúùëõùëÄùëéùëù)

ùëπùë¨ùëªùëºùëπùëµ ùëÉùëúùëñùëõt



Input:
    o ùë†ùëúùë¢ùëüùëêùëíùêºùëöùëéùëîùëí, ùë°ùëíùëöùëùùëôùëéùë°ùëíùêºùëöùëéùëîùëí
    o ùë†ùëíùëîùëöùëíùëõùë°ùëéùë°ùëñùëúùëõùëÖùëíùë†ùë¢ùëôùë°
    o ùëöùëñùëõùëÄùëúùëëùëñùëìùë¶, ùëöùëéùë•ùëÄùëúùëëùëñùëìùë¶
Output:
    o ùëîùëúùëúùëëùëÉùëúùëñùëõùë°ÔøΩ

SET ùëöùëñùëõùë¢ùë†ùëÄùëúùëëùëñùëìùë¶ùê¥ùëõùëîùëôùëí ‚Üê ùëéùëüùëüùëéùë¶ùëÖùëéùëõùëîùëí[ ‚àí1, ùëöùëñùëõùëÄùëúùëëùëñùëìùë¶, ‚àí1] 
SET ùëùùëôùë¢ùë†ùëÄùëúùëëùëñùëìùë¶ùê¥ùëõùëîùëôùëí ‚Üê ùëéùëüùëüùëéùë¶ùëÖùëéùëõùëîùëí[ 1, ùëöùëéùë•ùëÄùëúùëëùëñùëìùë¶, 1 ]

SET ùëîùëúùëúùëëùëÉùëúùëñùëõùë°ùë† ‚Üê ùëíùëöùëùùë°ùë¶ùêøùëñùë†ùë°[]

CONVERT ùë†ùëúùë¢ùëüùëêùëíùêºùëöùëéùëîùëí ‚Üí ùëîùëüùëéùë¶ùëÜùëêùëéùëôùëí ùë®ùë∫ ùëñùëöùëî
CONVERT ùë°ùëíùëöùëùùëôùëéùë°ùëíùêºùëöùëéùëîùëí ‚Üí ùëîùëüùëéùë¶ùëÜùëêùëéùëôùëí ùë®ùë∫ ùë°ùëíùëöùëùÔøΩ

FOR ùëèùëúùë•, ùëéùëõùëîùëôùëí ùë≠ùëπùë∂ùë¥ ùë†ùëíùëîùëöùëíùëõùë°ùëéùë°ùëñùëúùëõùëÖùëíùë†ùë¢ùëôs
    ARRAY ùëöùëñùëõùë¢ùë†ùëÜùë¢ùëèùê¥ùëõùëîùëôùëíùë† ‚Üê ùëéùëõùëîùëôùëí + ùëöùëñùëõùë¢ùë†ùëÄùëúùëëùëñùëìùë¶ùê¥ùëõùëîùëôùëí
    ARRAY ùëùùëôùë¢ùë†ùëÜùë¢ùëèùê¥ùëõùëîùëôùëíùë† ‚Üê ùëéùëõùëîùëôùëí + ùëùùëôùë¢ùë†ùëÄùëúùëëùëñùëìùë¶ùê¥ùëõùëîùëôùëí
    SET ùëöùëñùëõùë¢ùë†ùëÉùëúùëñùëõùë°ùëíùëü, ùëùùëôùë¢ùë†ùëÉùëúùëñùëõùë°ùëíùëü ‚Üê 0, 0
    SET ùëöùëñùëõùë¢ùë†ùê∂‚Ñéùëíùëêùëò, ùëùùëôùë¢ùë†ùê∂‚Ñéùëíùëêùëò ‚Üê ùë≠ùë®ùë≥ùë∫ùë¨,ùë≠ùë®ùë≥ùë∫ùë¨
    SET ùë†ùë¢ùëèùëÄùëñùëõùë¢ùë†ùëÉùëúùëñùëõùë°ùë†, ùë†ùë¢ùëèùëÉùëôùë¢ùë†ùëÉùëúùëñùëõùë°ùë† ‚Üê ùëíùëöùëùùë°ùë¶ùêøùëñùë†ùë°[], ùëíùëöùëùùë°ùë¶ùêøùëñùë†ùë°[]
    SET ùë°‚Ñéùëí ùëôùëéùë†ùë° ùëíùëôùëíùëöùëíùëõùë° ùëúùëì ùë†ùë¢ùëèùëÄùëñùëõùë¢ùë†ùëÉùëúùëñùëõùë°ùë† ùë®ùë∫ ùëöùëñùëõùë¢ùë†ùêøùëÉ
    SET ùë°‚Ñéùëí ùëôùëéùë†ùë° ùëíùëôùëíùëöùëíùëõùë° ùëúùëì ùë†ùë¢ùëèùëÉùëôùë¢ùë†ùëÉùëúùëñùëõùë°ùë† ùë®ùë∫ ùëùùëôùë¢ùë†ùêøùëÉ
    ùë™ùë®ùë≥ùë≥ ùëöùëéùë°ùëê‚Ñéùëáùëíùëöùëùùëôùëéùë°ùëí(ùëñùëöùëî,ùë°ùëíùëöùëùùëô, ùëèùëúùë•, ùëéùëõùëîùëôùëí) ùëπùë¨ùëªùëºùëπùëµ ùëëùëíùëìùëéùë¢ùëôùë°ùëÉùëúùëñùëõùë° ùë®ùë∫ P

ùëæùëØùë∞ùë≥ùë¨ ùëöùëñùëõùë¢ùë†ùê∂‚Ñéùëíùëêùëò = ùë≠ùë®ùë≥ùë∫ùë¨ ùë®ùëµùë´ ùëùùëôùë¢ùë†ùê∂‚Ñéùëíùëêùëò = ùë≠ùë®ùë≥ùë∫ùë¨
    CALL
    ùëöùëéùë°ùëê‚Ñéùëáùëíùëöùëùùëôùëéùë°ùëí(ùëñùëöùëî,ùë°ùëíùëöùëùùëô, ùëèùëúùë•, ùëöùëñùëõùë¢ùë†ùëÜùë¢ùëèùê¥ùëõùëîùëôùëíùë† ùëöùëñùëõùë¢ùë†ùëÉùëúùëñùëõùë°ùëíùëü )ùëπùë¨ùëªùëºùëπùëµùëöùëñùëõùë¢ùë†ùëÉùëúùëñùëõùë°
    CALL ùëöùëéùë°ùëê‚Ñéùëáùëíùëöùëùùëôùëéùë°ùëí(ùëñùëöùëî,ùë°ùëíùëöùëùùëô, ùëèùëúùë•, ùëùùëôùë¢ùë†ùëÜùë¢ùëèùê¥ùëõùëîùëôùëíùë† ùëùùëôùë¢ùë†ùëÉùëúùëñùëõùë°ùëíùëü ) ùëπùë¨ùëªùëºùëπùëµ ùëùùëôùë¢ùë†ùëÉùëúùëñùëõùë°
    ùë∞ùë≠ ùëöùëñùëõùë¢ùë†ùëÉùëúùëñùëõùë°ùëíùëü = 0
    ùëöùëñùëõùë¢ùë†ùê∂‚Ñéùëíùëêùëò ‚Üê ùë©ùë∂ùë∂ùë≥(ùë†ùëêùëúùëüùëíùëúùëì(ùëöùëñùëõùë¢ùë†ùëÉùëúùëñùëõùë°) < ùë†ùëêùëúùëüùëíùëúùëì(ùëÉ))
    ùë¨ùë≥ùë∫ùë¨
    ùëöùëñùëõùë¢ùë†ùê∂‚Ñéùëíùëêùëò ‚Üê ùë©ùë∂ùë∂ùë≥(ùë†ùëêùëúùëüùëíùëúùëì(ùëöùëñùëõùë¢ùë†ùëÉùëúùëñùëõùë°) < ùë†ùëêùëúùëüùëíùëúùëì(ùëöùëñùëõùë¢ùë†ùêøùëÉ))
    ùë¨ùëµùë´ùë∞F
    ùë∞ùë≠ ùëµùë∂ùëª ùëöùëñùëõùë¢ùë†ùê∂‚Ñéùëíùëêùëò
    ùë®ùë´ùë´ ùëöùëñùëõùë¢ùë†ùëÉùëúùëñùëõùë° ‚Üí ùë†ùë¢ùëèùëÄùëñùëõùë¢ùë†ùëÉùëúùëñùëõùë°ùë†
    ùëöùëñùëõùë¢ùë†ùëÉùëúùëñùëõùë°ùëíùëü ‚Üê ùëöùëñùëõùë¢ùë†ùëÉùëúùëñùëõùë°ùëíùëü + 1
    ENDIF
    ùë∞ùë≠ ùëùùëôùë¢ùë†ùëÉùëúùëñùëõùë°ùëíùëü = 0
    ùëùùëôùë¢ùë†ùê∂‚Ñéùëíùëêùëò ‚Üê ùë©ùë∂ùë∂ùë≥(ùë†ùëêùëúùëüùëíùëúùëì(ùëùùëôùë¢ùë†ùëÉùëúùëñùëõùë°) < ùë†ùëêùëúùëüùëíùëúùëì(ùëÉ))
    ùë¨ùë≥ùë∫ùë¨
    ùëùùëôùë¢ùë†ùê∂‚Ñéùëíùëêùëò ‚Üê ùë©ùë∂ùë∂ùë≥(ùë†ùëêùëúùëüùëíùëúùëì(ùëùùëôùë¢ùë†ùëÉùëúùëñùëõùë°) < ùë†ùëêùëúùëüùëíùëúùëì(ùëùùëôùë¢ùë†ùêøùëÉ))
    ùë¨ùëµùë´ùë∞ùë≠
    ùë∞ùë≠ ùëµùë∂ùëª ùëùùëôùë¢ùë†ùê∂‚Ñéùëíùëêùëò
    ùë®ùë´ùë´ ùëùùëôùë¢ùë†ùëÉùëúùëñùëõùë° ‚Üí ùë†ùë¢ùëèùëÉùëôùë¢ùë†ùëÉùëúùëñùëõùë°ùë†
    ùëùùëôùë¢ùë†ùëÉùëúùëñùëõùë°ùëíùëü ‚Üê ùëùùëôùë¢ùë†ùëÉùëúùëñùëõùë°ùëíùëü + 1
    ùë¨ùëµùë´ùë∞ÔøΩ
    Eùëµùë´ùëæùëØùë∞ùë≥ùë¨
    ùëèùëíùë†ùë°ùëÉùëúùëñùëõùë° ‚Üê ùëöùëéùë•ùëùùëúùëñùëõùë°
    (ùë†ùëêùëúùëüùëíùëúùëì ùëÉ, ùëöùëñùëõùë¢ùë†ùêøùëÉ, ùëùùëôùë¢ùë†ùêøùëÉ )
    ùë®ùë´ùë´ ùëèùëíùë†ùë°ùëÉùëúùëñùëõùë° ‚Üí ùëîùëúùëúùëëùëÉùëúùëñùëõùë°ùë†
ENDFOR
