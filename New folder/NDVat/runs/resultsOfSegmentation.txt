boxes: Đây là tensor chứa các thông tin về bounding boxes của các đối tượng được phát hiện trong hình ảnh. Mỗi dòng của tensor này tương ứng với một bounding box và bao gồm các thông tin sau:

Cột 1 và 2: Tọa độ x và y của góc trên bên trái của bounding box.
Cột 3 và 4: Tọa độ x và y của góc dưới bên phải của bounding box.
Cột 5: Độ tự tin (confidence) của việc phát hiện.
Cột 6: ID của lớp (class ID) của đối tượng được phát hiện.
cls: Đây là tensor chứa ID của lớp của các đối tượng được phát hiện.

conf: Đây là tensor chứa giá trị độ tự tin (confidence) của các đối tượng được phát hiện.

data: Tương tự như boxes, đây là tensor chứa thông tin về bounding boxes của các đối tượng, nhưng được tổ chức theo cấu trúc tensor khác.

id: Đây là một thuộc tính (attribute) không có giá trị cụ thể trong kết quả.

is_track: Đây là một thuộc tính (attribute) đánh dấu xem liệu các bounding boxes có phải là theo dõi các đối tượng hay không.

orig_shape: Đây là kích thước gốc của hình ảnh trước khi được xử lý bởi mô hình.

shape: Đây là kích thước của hình ảnh sau khi được xử lý bởi mô hình.

xywh: Đây là tensor chứa thông tin về tọa độ và kích thước của bounding boxes dưới dạng (x_center, y_center, width, height).

xywhn: Đây là tensor chứa thông tin tương tự xywh, nhưng được chuẩn hóa trong khoảng từ 0 đến 1.

xyxy: Đây là tensor chứa thông tin về tọa độ của bounding boxes dưới dạng (x_min, y_min, x_max, y_max).

xyxyn: Đây là tensor chứa thông tin tương tự xyxy, nhưng được chuẩn hóa trong khoảng từ 0 đến 1.



Thông tin về mask trong ultralytics.engine.results.Masks bao gồm:

data và masks: Đây là hai tensor có cùng kích thước, đại diện cho mask của các vật thể trong hình ảnh. Mỗi tensor có kích thước (1, H, W), trong đó H là chiều cao của mask và W là chiều rộng của mask. Mask được biểu diễn dưới dạng ma trận các giá trị số thực trong khoảng từ 0 đến 1, trong đó 0 thường đại diện cho vùng không có vật thể và 1 đại diện cho vùng chứa vật thể.

orig_shape: Kích thước của hình ảnh gốc trước khi được thay đổi kích thước để phù hợp với mô hình.

segments: Một danh sách các điểm trên biên của mask, mỗi điểm được biểu diễn bằng tọa độ (x, y) trên ma trận mask.

shape: Kích thước của tensor mask, có dạng (1, H, W), trong đó H là chiều cao của mask và W là chiều rộng của mask.

xy và xyn: xy là danh sách các điểm trên biên của mask, mỗi điểm được biểu diễn bằng tọa độ (x, y) trong định dạng tensor. xyn là danh sách tọa độ của các điểm trên biên của mask được chuẩn hóa trong khoảng từ 0 đến 1, thường được sử dụng để vẽ mask trên hình ảnh.

Với thông tin này, bạn có thể truy cập và xử lý mask của các vật thể được phát hiện trong hình ảnh.


/////////////////////////////////

OpenCV cung cấp một số phương pháp để xác định góc quay của một vật trong một ảnh. Dưới đây là một số cách thường được sử dụng:

Sử dụng Hough Line Transform (Biến đổi Hough cho đường thẳng): Đây là một trong những phương pháp phổ biến để xác định góc quay của vật thể trên ảnh. Bạn có thể sử dụng hàm cv2.HoughLines() để tìm các đường thẳng trong ảnh sau đó tính toán góc giữa đường thẳng và trục tọa độ.

Sử dụng Feature Matching (Khớp đặc trưng): Bạn có thể sử dụng thuật toán khớp đặc trưng như SIFT (Scale-Invariant Feature Transform) hoặc SURF (Speeded-Up Robust Features) để tìm các điểm đặc trưng trên vật thể và sau đó tính toán góc quay từ các điểm này.

=>> (không dùng được) Sử dụng Contour Detection (Phát hiện đường viền): Nếu vật thể có hình dạng đặc trưng, bạn có thể sử dụng hàm cv2.findContours() để tìm đường viền của vật thể và sau đó tính toán góc quay dựa trên hướng của đường viền.

Sử dụng Homography: Nếu bạn có một vật thể với biến đổi homography (một loại biến đổi affine hoặc perspective), bạn có thể sử dụng hàm cv2.findHomography() để xác định ma trận homography và sau đó tính toán góc quay từ ma trận này.

Dưới đây là một ví dụ sử dụng phương pháp Hough Line Transform để xác định góc quay của vật thể trong ảnh:





////////////////////////////////////


Để thêm tâm của bounding box vào ảnh, bạn có thể sử dụng thư viện OpenCV (hoặc một thư viện xử lý ảnh tương tự). Dưới đây là cách bạn có thể thực hiện điều này:

Trích xuất tọa độ tâm của bounding boxes từ tensor xywh (hoặc xyxy nếu bạn muốn).

Vẽ một điểm hoặc một đường trỏ tới tâm của bounding box trên ảnh gốc.

Dưới đây là một ví dụ về cách thực hiện điều này:

import cv2
import numpy as np

# Load the image
image = cv2.imread('/content/drive/MyDrive/NhanDienvat/NDVat/train/images/20230919_104657_jpg.rf.f419369aed5b63d2614e2c2014ef43e5.jpg')

# Extract the 'xywh' tensor from the results (assuming a single image prediction)
xywh = results.pred[0].xywh

# Iterate through bounding boxes and draw a dot at the center
for bbox in xywh:
    x_center, y_center, width, height = bbox[:4]
    x_center = int(x_center)
    y_center = int(y_center)
    cv2.circle(image, (x_center, y_center), 5, (0, 255, 0), -1)  # Draw a green circle at the center

# Save the image with center points
cv2.imwrite('/content/center_points.jpg', image)

# Display the image (optional)
cv2.imshow('Image with Center Points', image)
cv2.waitKey(0)
cv2.destroyAllWindows()

//////Để tính toán góc xoay của một đường thẳng nằm trong một hình ảnh, bạn có thể sử dụng một số phương pháp xử lý hình ảnh và toán học. Dưới đây là một cách tiêu biểu để thực hiện điều này:

Phát hiện đường thẳng: Đầu tiên, bạn cần phát hiện đường thẳng trong hình ảnh. OpenCV cung cấp một số phương pháp phát hiện đường thẳng, chẳng hạn như cv2.HoughLines hoặc cv2.HoughLinesP dựa trên biến đổi Hough.

Tính toán góc xoay: Sau khi bạn đã có danh sách các đường thẳng được phát hiện, bạn có thể tính toán góc xoay của mỗi đường thẳng. Để làm điều này, bạn có thể sử dụng hàm toán học như atan2 (tính toán góc dựa trên các tọa độ của đầu mút của đường thẳng) hoặc arctan (tính toán góc dựa trên hệ số góc của đường thẳng).

Dưới đây là một ví dụ cụ thể sử dụng OpenCV để tính toán góc xoay của đường thẳng:

python
Copy code
import cv2
import numpy as np

# Đọc hình ảnh
image = cv2.imread('image_with_line.jpg', cv2.IMREAD_GRAYSCALE)

# Phát hiện đường thẳng bằng biến đổi Hough
lines = cv2.HoughLines(image, 1, np.pi / 180, threshold=100)

# Tính toán góc xoay của từng đường thẳng và chuyển đổi thành độ
for rho, theta in lines[:, 0]:
    angle = theta * 180 / np.pi
    print(f'Góc xoay: {angle} độ')

# Hiển thị hình ảnh với đường thẳng đã phát hiện
for rho, theta in lines[:, 0]:
    a = np.cos(theta)
    b = np.sin(theta)
    x0 = a * rho
    y0 = b * rho
    x1 = int(x0 + 1000 * (-b))
    y1 = int(y0 + 1000 * (a))
    x2 = int(x0 - 1000 * (-b))
    y2 = int(y0 - 1000 * (a))
    cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)

cv2.imshow('Image with Lines', image)
cv2.waitKey(0)
cv2.destroyAllWindows()


///////////////////////////////////////////////xac dinh huong orientation.py

# from __future__ import print_function
# from __future__ import division
import cv2 as cv
import numpy as np
import argparse
from math import atan2, cos, sin, sqrt, pi
def drawAxis(img, p_, q_, colour, scale,degree):
 p = list(p_)
 q = list(q_)
 print("diemP: ",p)
 print("diemQ: ",q)
 text1 = f"({p[0]}, {p[1]})"
 
 cv.putText(img, text1, (p[0]+30,p[1]+30), cv.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2)
 angle = atan2(p[1] - q[1], p[0] - q[0]) # angle in radians
 print("angle: ",degree)
 text2 = f"({degree})"
 cv.putText(img, text2, (p[0]+150,p[1]-30), cv.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2)

 hypotenuse = sqrt((p[1] - q[1]) * (p[1] - q[1]) + (p[0] - q[0]) * (p[0] - q[0]))
 # Here we lengthen the arrow by a factor of scale
 q[0] = p[0] - scale * hypotenuse * cos(angle)
 q[1] = p[1] - scale * hypotenuse * sin(angle)
 cv.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 5, cv.LINE_AA)
 # create the arrow hooks
 p[0] = q[0] + 9 * cos(angle + pi / 4)
 p[1] = q[1] + 9 * sin(angle + pi / 4)
 cv.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 5, cv.LINE_AA)
 p[0] = q[0] + 9 * cos(angle - pi / 4)
 p[1] = q[1] + 9 * sin(angle - pi / 4)
 cv.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 5, cv.LINE_AA)
 
def getOrientation(pts, img):
 
 sz = len(pts)
 data_pts = np.empty((sz, 2), dtype=np.float64)
 for i in range(data_pts.shape[0]):
  data_pts[i,0] = pts[i,0,0]
  data_pts[i,1] = pts[i,0,1]
 # Perform PCA analysis
 mean = np.empty((0))
 mean, eigenvectors, eigenvalues = cv.PCACompute2(data_pts, mean)
 # Store the center of the object
 cntr = (int(mean[0,0]), int(mean[0,1]))
 
 
 cv.circle(img, cntr, 3, (255, 0, 255), 2)
 p1 = (cntr[0] + 0.02 * eigenvectors[0,0] * eigenvalues[0,0], cntr[1] + 0.02 * eigenvectors[0,1] * eigenvalues[0,0])
 p2 = (cntr[0] - 0.02 * eigenvectors[1,0] * eigenvalues[1,0], cntr[1] - 0.02 * eigenvectors[1,1] * eigenvalues[1,0])

 angle = atan2(eigenvectors[0,1], eigenvectors[0,0]) # orientation in radians
 degree = angle * (180 / np.pi)

 drawAxis(img, cntr, p1, (0, 255, 0), 1,degree)
 drawAxis(img, cntr, p2, (255, 255, 0), 5,degree)

 
 return degree
parser = argparse.ArgumentParser(description='Code for Introduction to Principal Component Analysis (PCA) tutorial.\
 This program demonstrates how to use OpenCV PCA to extract the orientation of an object.')
parser.add_argument('--input', help='Path to input image.', default='pca_test1.jpg')
args = parser.parse_args()
src = cv.imread(cv.samples.findFile(args.input))


# Xác định các tọa độ của hình ảnh bạn muốn cắt
# x, y, width, height = 900, 900, 1200, 1000  # Ví dụ: cắt từ (100, 100) đến (300, 300)

# Thực hiện phép cắt
# src = image[y:y+height, x:x+width]

# Check if image is loaded successfully
if src is None:
 print('Could not open or find the image: ', args.input)
 exit(0)
# cv.imshow('src', src)
# Convert image to grayscale
gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)
# Convert image to binary
_, bw = cv.threshold(gray, 50, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)
contours, _ = cv.findContours(bw, cv.RETR_LIST, cv.CHAIN_APPROX_NONE)
for i, c in enumerate(contours):
 # Calculate the area of each contour
 area = cv.contourArea(c)
 # Ignore contours that are too small or too large
 if area < 1e2 or 1e5 < area:
  continue
 # Draw each contour only for visualisation purposes
 cv.drawContours(src, contours, i, (0, 0, 255), 2)
 # Find the orientation of each shape
 getOrientation(c, src)
 cv.imwrite('orientation_image.jpg',src)
# cv.imshow('output', src)
# cv.waitKey()


///////////////////////////////////////////////xac dinh huong orientation.py

# from __future__ import print_function
# from __future__ import division
import cv2 as cv
import numpy as np
import argparse
from math import atan2, cos, sin, sqrt, pi
def drawAxis(img, p_, q_, colour, scale,degree):
 p = list(p_)
 q = list(q_)
 print("diemP: ",p)
 print("diemQ: ",q)
 text1 = f"({p[0]}, {p[1]})"
 
 cv.putText(img, text1, (p[0]+30,p[1]+30), cv.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2)
 angle = atan2(p[1] - q[1], p[0] - q[0]) # angle in radians
 print("angle: ",degree)
 text2 = f"({degree})"
 cv.putText(img, text2, (p[0]+150,p[1]-30), cv.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2)

 hypotenuse = sqrt((p[1] - q[1]) * (p[1] - q[1]) + (p[0] - q[0]) * (p[0] - q[0]))
 # Here we lengthen the arrow by a factor of scale
 q[0] = p[0] - scale * hypotenuse * cos(angle)
 q[1] = p[1] - scale * hypotenuse * sin(angle)
 cv.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 5, cv.LINE_AA)
 # create the arrow hooks
 p[0] = q[0] + 9 * cos(angle + pi / 4)
 p[1] = q[1] + 9 * sin(angle + pi / 4)
 cv.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 5, cv.LINE_AA)
 p[0] = q[0] + 9 * cos(angle - pi / 4)
 p[1] = q[1] + 9 * sin(angle - pi / 4)
 cv.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 5, cv.LINE_AA)
 
def getOrientation(pts, img):
 
 sz = len(pts)
 data_pts = np.empty((sz, 2), dtype=np.float64)
 for i in range(data_pts.shape[0]):
  data_pts[i,0] = pts[i,0,0]
  data_pts[i,1] = pts[i,0,1]
 # Perform PCA analysis
 mean = np.empty((0))
 mean, eigenvectors, eigenvalues = cv.PCACompute2(data_pts, mean)
 # Store the center of the object
 cntr = (int(mean[0,0]), int(mean[0,1]))
 
 
 cv.circle(img, cntr, 3, (255, 0, 255), 2)
 p1 = (cntr[0] + 0.02 * eigenvectors[0,0] * eigenvalues[0,0], cntr[1] + 0.02 * eigenvectors[0,1] * eigenvalues[0,0])
 p2 = (cntr[0] - 0.02 * eigenvectors[1,0] * eigenvalues[1,0], cntr[1] - 0.02 * eigenvectors[1,1] * eigenvalues[1,0])

 angle = atan2(eigenvectors[0,1], eigenvectors[0,0]) # orientation in radians
 degree = angle * (180 / np.pi)

 drawAxis(img, cntr, p1, (0, 255, 0), 1,degree)
 drawAxis(img, cntr, p2, (255, 255, 0), 5,degree)

 
 return degree
parser = argparse.ArgumentParser(description='Code for Introduction to Principal Component Analysis (PCA) tutorial.\
 This program demonstrates how to use OpenCV PCA to extract the orientation of an object.')
parser.add_argument('--input', help='Path to input image.', default='pca_test1.jpg')
args = parser.parse_args()
src = cv.imread(cv.samples.findFile(args.input))


# Xác định các tọa độ của hình ảnh bạn muốn cắt
# x, y, width, height = 900, 900, 1200, 1000  # Ví dụ: cắt từ (100, 100) đến (300, 300)

# Thực hiện phép cắt
# src = image[y:y+height, x:x+width]

# Check if image is loaded successfully
if src is None:
 print('Could not open or find the image: ', args.input)
 exit(0)
# cv.imshow('src', src)
# Convert image to grayscale
gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)
# Convert image to binary
_, bw = cv.threshold(gray, 50, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)
contours, _ = cv.findContours(bw, cv.RETR_LIST, cv.CHAIN_APPROX_NONE)
for i, c in enumerate(contours):
 # Calculate the area of each contour
 area = cv.contourArea(c)
 # Ignore contours that are too small or too large
 if area < 1e2 or 1e5 < area:
  continue
 # Draw each contour only for visualisation purposes
 cv.drawContours(src, contours, i, (0, 0, 255), 2)
 # Find the orientation of each shape
 getOrientation(c, src)
 cv.imwrite('orientation_image.jpg',src)
# cv.imshow('output', src)
# cv.waitKey()


//////////////////////////////////////////////



# ///////////////////////////////////////////////////////////

from ultralytics import YOLO
import cv2
import numpy as np

import argparse
from math import atan2, cos, sin, sqrt, pi
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors

link = r'/content/nhandienvat/detectByYolov8/dataset_specialItems/train/images/20230922_154950_jpg.rf.a55265100fc54aa788b672e6a11b49f2.jpg'

image = cv2.imread(link)

def drawAxis(img, p_, q_, colour, scale,degree):
 p = list(p_)
 q = list(q_)
 print("diemP: ",p)
 print("diemQ: ",q)
 text1 = f"({p[0]}, {p[1]})"
 
#  cv.putText(img, text1, (p[0]+30,p[1]+30), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 1)
 angle = atan2(p[1] - q[1], p[0] - q[0]) # angle in radians
 print("angle: ",degree)
 text2 = f"{round(degree,2)} degree"
 cv2.putText(img, text2, (p[0]+10,p[1]-30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 1)

 hypotenuse = sqrt((p[1] - q[1]) * (p[1] - q[1]) + (p[0] - q[0]) * (p[0] - q[0]))
 # Here we lengthen the arrow by a factor of scale
 q[0] = p[0] - scale * hypotenuse * cos(angle)
 q[1] = p[1] - scale * hypotenuse * sin(angle)
 cv2.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 1, cv2.LINE_AA)
 # create the arrow hooks
 p[0] = q[0] + 9 * cos(angle + pi / 4)
 p[1] = q[1] + 9 * sin(angle + pi / 4)
 cv2.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 1, cv2.LINE_AA)
 p[0] = q[0] + 9 * cos(angle - pi / 4)
 p[1] = q[1] + 9 * sin(angle - pi / 4)
 cv2.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 1, cv2.LINE_AA)
 
def getOrientation(pts, img):
 sz = len(pts)
 data_pts = np.empty((sz, 2), dtype=np.float64)
 for i in range(data_pts.shape[0]):
  data_pts[i,0] = pts[i,0,0]
  data_pts[i,1] = pts[i,0,1]
 # Perform PCA analysis
 mean = np.empty((0))
 mean, eigenvectors, eigenvalues = cv2.PCACompute2(data_pts, mean)
 # Store the center of the object
 cntr = (int(mean[0,0]), int(mean[0,1]))
 
 
 cv2.circle(img, cntr, 2, (255, 0, 255), 1)
 p1 = (cntr[0] + 0.02 * eigenvectors[0,0] * eigenvalues[0,0], cntr[1] + 0.02 * eigenvectors[0,1] * eigenvalues[0,0])
 p2 = (cntr[0] - 0.02 * eigenvectors[1,0] * eigenvalues[1,0], cntr[1] - 0.02 * eigenvectors[1,1] * eigenvalues[1,0])
#  cv.circle(img, (eigenvectors[0,1], eigenvectors[0,0]), 2, (0, 0, 255), 1)
 angle = atan2(eigenvectors[0,1], eigenvectors[0,0]) # orientation in radians
 degree = angle * (180 / np.pi)

 drawAxis(img, cntr, p1, (0, 255, 0), 2,degree)
 drawAxis(img, cntr, p2, (255, 255, 0), 5,degree)
 return degree


# beta = -50  # Giảm độ sáng

# # Sử dụng hàm cv2.convertScaleAbs để giảm độ sáng của ảnh
# src = cv2.convertScaleAbs(image, alpha=1, beta=beta)


# # Check if image is loaded successfully
# if src is None:
# #  print('Could not open or find the image: ', args.input)
#  exit(0)
# # cv2.imshow('src', src)
# # Convert image to grayscale
# gray_picture = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)

# gray_inverted = cv2.bitwise_not(gray_picture)
# # Convert image to binary
# _, bw = cv2.threshold(gray_picture, 50, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
# contours, _ = cv2.findContours(bw, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)
# for i, c in enumerate(contours):
#  # Calculate the area of each contour
#  area = cv2.contourArea(c)
#  # Ignore contours that are too small or too large
#  if area < 1e2*3 or 1e5 < area:
#   continue
#  # Draw each contour only for visualisation purposes
#  cv2.drawContours(src, contours, i, (0, 0, 255), 2)
#  # Find the orientation of each shape
#  getOrientation(c, src)
#  cv2.imwrite('orientation_image.jpg',src)
# //////////////
# cv2.imshow('output', src)
# Assuming you have a grayscale image in the 'gray_picture' variable
# Normalize the grayscale values to be between 0 and 1

# plt.imshow(bw, cmap="gray")
# plt.title("Bitwise Gray")
# plt.axis("off")
# plt.show()

# plt.imshow(gray_inverted, cmap="gray")
# plt.title("gray_inverted Gray")
# plt.axis("off")
# plt.show()

# ///////////////////////////////////

# Load a model
model = YOLO('yolov8n-seg.pt')  # load an official model
model = YOLO(r'/content/nhandienvat/runs/segment/train/weights/best.pt')  # load a custom model

# Predict with the model
results = model(r"/content/nhandienvat/detectByYolov8/dataset_specialItems/train/images/20230922_154950_jpg.rf.a55265100fc54aa788b672e6a11b49f2.jpg", save = True)  # predict on an image


myList = []

mylistmask = []

checkitem = []
for r in results:
    # mylistmask = r.masks.xy #ssử dụng nếu dùng phương pháp tìm tọa độ tâm theo các điểm masks
    # print("mask: ",r.masks[0].xy[0])
    # print("shape: ",r.masks.shape)
    # print("masks: ",r.masks)
    print("boxes: ",r.boxes)  # print the Boxes object containing the detection bounding boxes
    myList = r.boxes.xywh.tolist()
    checkitem = r.boxes.cls.tolist()
    # print(int(checkitem[2]))
print("myList: ",myList)
print("length: ",len(myList))


# print(list)
count = 0

while count < len(checkitem):
  print("count: ",count)
  if(checkitem[count] == 3.0):
    print("3")
    bBoxitem = myList[count]
    mask = np.zeros_like(image, dtype=np.uint8)
#     # Định nghĩa màu xanh mà bạn muốn sử dụng (ví dụ: màu xanh lá cây)
#     green_color = ( 255,255, 0)  # Xanh lá cây: (B, G, R)

# # Gán giá trị màu xanh cho mặt nạ
#     mask[:, :] = green_color

    a = (bBoxitem[0] - bBoxitem[2]/2, bBoxitem[1] - bBoxitem[3]/2)
    b = (bBoxitem[0] + bBoxitem[2]/2, bBoxitem[1] - bBoxitem[3]/2)
    c = (bBoxitem[0] + bBoxitem[2]/2, bBoxitem[1] + bBoxitem[3]/2)
    d = (bBoxitem[0] - bBoxitem[2]/2, bBoxitem[1] + bBoxitem[3]/2)

    points = np.array([a, b,c ,d], dtype=np.int32)
    cv2.fillPoly(mask, [points], (255, 255, 255))
    src = cv2.bitwise_and(image, mask)
    beta = -50  # Giảm độ sáng
        # Sử dụng hàm cv2.convertScaleAbs để giảm độ sáng của ảnh
    result = cv2.convertScaleAbs(src, alpha=1, beta=beta)


    # Check if image is loaded successfully
    if result is None:
    #  print('Could not open or find the image: ', args.input)
        exit(0)
    # cv2.imshow('src', src)
    # Convert image to grayscale
    gray_picture = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)

    gray_inverted = cv2.bitwise_not(gray_picture)
    # Convert image to binary
    _, bw = cv2.threshold(gray_picture, 50, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
    # cv2.imwrite('bibi.jpg', bw)
    
    contours, _ = cv2.findContours(bw, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)
    for i, c in enumerate(contours):
    # Calculate the area of each contour
      area = cv2.contourArea(c)
    # Ignore contours that are too small or too large
      if area < 1e2*3 or 1e5 < area:
        continue
    # Draw each contour only for visualisation purposes
        cv2.drawContours(result, contours, i, (0, 0, 255), 2)
    # Find the orientation of each shape
      kq =  getOrientation(c, result)
      print("kq: ", kq)
  if checkitem[count] == 4.0:

    list = myList[count]
    point = (list[0],list[1])
    print("point :",point)
    color = (0, 255, 0)
    # Kích thước của điểm
    thickness = -1  # Đặt -1 để vẽ một điểm đầy đủ
    # Vẽ điểm trên hình ảnh
    cv2.circle(image, (int(list[0]),int(list[1])), 3, (0, 0, 255), thickness) #chấm điểm vào ảnh ở tọa độ tâm của bounding box của lỗ tâm
    # in tọa độ của tâm
    text = f"({int(list[0])}, {int(list[1])})"
    cv2.putText(image, text, (int(list[0])+30,int(list[1])+30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
    cv2.line(image, (int(list[0]),int(list[1])), (int(list[0]) + 50, int(list[1])), (0, 0, 255), 2)  # Vẽ trục X (màu đỏ)
    cv2.line(image, (int(list[0]),int(list[1])), (int(list[0]), int(list[1]) + 50), (0, 255, 0), 2)  # Vẽ trục Y (màu xanh lá)
  count = count + 1
# print("list masks: ",mylistmask.tolist()[0])



# ///////////////////Cách lấy tâm từ các điểm masks/////////////
# count = 0
# while count < len(mylistmask):
#   if checkitem[count] == 4.0:
#     print("count: ", count)
#     print(mylistmask[count].tolist())
#     listitem = mylistmask[count].tolist()
#     count2 = 0
#     totalx= 0
#     totaly = 0
#     x = 0
#     y = 0
    
#     while count2 < len(listitem):
#       print(listitem[count2])
#       coodinate = listitem[count2]
#       totalx = totalx + coodinate[0]
#       totaly = totaly + coodinate[1]
#       # cv2.circle(image, (int(coodinate[0]),int(coodinate[1])), 3, color, thickness)
#       cv2.drawMarker(image, (int(coodinate[0]),int(coodinate[1])), color, markerType=cv2.MARKER_STAR, markerSize=2)
#       count2 = count2 + 1
#     x = totalx / len(listitem)
#     y = totaly / len(listitem)
#     cv2.drawMarker(image, (int(x),int(y)), color, markerType=cv2.MARKER_STAR, markerSize=2)
#   count = count + 1


cv2.imwrite('output_image2.jpg', image)
cv2.imwrite('output_image3.jpg', result)


#Kết luận rằng lấy tâm của bounding box của lỗ tâm chuẩn hơn cách lấy tâm từ các điểm masks của lỗ tâm 
